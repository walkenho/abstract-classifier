{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# --- Configture Notebook ------\n",
    "# show all outputs of cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import black\n",
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load(\n",
    "    lab=True,\n",
    "    line_length=100,\n",
    "    verbosity=\"DEBUG\",\n",
    "    target_version=black.TargetVersion.PY310,\n",
    ")\n",
    "\n",
    "# enable automatic reloading\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import plotly.express as px\n",
    "from sklearn.pipeline import FunctionTransformer, Pipeline\n",
    "from arxiv_article_classifier.data.load import load_processed_data\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from pandas.core.base import PandasObject\n",
    "from arxiv_article_classifier.utils import display_fully\n",
    "\n",
    "PandasObject.display_fully = display_fully\n",
    "\n",
    "DATAFOLDER = Path().cwd().parent / \"data\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "DATAFOLDER_INTERIM = Path().cwd().parent / \"data\" / \"interim\"\n",
    "DATAFOLDER_PROCESSED = Path().cwd().parent / \"data\" / \"processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_raw, _, _, y_train, _, _), labels = load_processed_data(DATAFOLDER_INTERIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Vision-based formation control systems recently have attracted attentions\\nfrom both the research community and the industry for its applicability in\\nGPS-denied environments. The safety assurance for such systems is challenging\\ndue to the lack of formal specifications for computer vision systems and the\\ncomplex impact of imprecise estimations on distributed control. We propose a\\ntechnique for safety assurance of vision-based formation control. Our technique\\ncombines (1) the construction of a piecewise approximation of the worst-case\\nerror of perception and (2) a classical Lyapunov-based safety analysis of the\\nconsensus control algorithm. The analysis provides the ultimate bound on the\\nrelative distance between drones. This ultimate bound can then be used to\\nguarantee safe separation of all drones. We implement an instance of the\\nvision-based control system on top of the photo-realistic AirSim simulator. We\\nconstruct the piecewise approximation for varying perception error under\\ndifferent environments and weather conditions, and we are able to validate the\\nsafe separation provided by our analysis across the different weather\\nconditions with AirSim simulation.',\n",
       "       'An optimization problem is at the heart of many robotics estimating,\\nplanning, and optimum control problems. Several attempts have been made at\\nmodel-based multi-robot localization, and few have formulated the multi-robot\\ncollaborative localization problem as a factor graph problem to solve through\\ngraph optimization. Here, the optimization objective is to minimize the errors\\nof estimating the relative location estimates in a distributed manner. Our\\nnovel graph-theoretic approach to solving this problem consists of three major\\ncomponents; (connectivity) graph formation, expansion through transition model,\\nand optimization of relative poses. First, we estimate the relative\\npose-connectivity graph using the received signal strength between the\\nconnected robots, indicating relative ranges between them. Then, we apply a\\nmotion model to formulate graph expansion and optimize them using g$^2$o graph\\noptimization as a distributed solver over dynamic networks. Finally, we\\ntheoretically analyze the algorithm and numerically validate its optimality and\\nperformance through extensive simulations. The results demonstrate the\\npracticality of the proposed solution compared to a state-of-the-art algorithm\\nfor collaborative localization in multi-robot systems.',\n",
       "       'As a promising learning paradigm integrating computation and communication,\\nfederated learning (FL) proceeds the local training and the periodic sharing\\nfrom distributed clients. Due to the non-i.i.d. data distribution on clients,\\nFL model suffers from the gradient diversity, poor performance, bad\\nconvergence, etc. In this work, we aim to tackle this key issue by adopting\\nimportance sampling (IS) for local training. We propose importance sampling\\nfederated learning (ISFL), an explicit framework with theoretical guarantees.\\nFirstly, we derive the convergence theorem of ISFL to involve the effects of\\nlocal importance sampling. Then, we formulate the problem of selecting optimal\\nIS weights and obtain the theoretical solutions. We also employ a water-filling\\nmethod to calculate the IS weights and develop the ISFL algorithms. The\\nexperimental results on CIFAR-10 fit the proposed theorems well and verify that\\nISFL reaps better performance, sampling efficiency, as well as explainability\\non non-i.i.d. data. To the best of our knowledge, ISFL is the first non-i.i.d.\\nFL solution from the local sampling aspect which exhibits theoretical\\ncompatibility with neural network models. Furthermore, as a local sampling\\napproach, ISFL can be easily migrated into other emerging FL frameworks.',\n",
       "       ...,\n",
       "       'The recent proliferation of 3D content that can be consumed on hand-held\\ndevices necessitates efficient tools for transmitting large geometric data,\\ne.g., 3D meshes, over the Internet. Detailed high-resolution assets can pose a\\nchallenge to storage as well as transmission bandwidth, and level-of-detail\\ntechniques are often used to transmit an asset using an appropriate bandwidth\\nbudget. It is especially desirable for these methods to transmit data\\nprogressively, improving the quality of the geometry with more data. Our key\\ninsight is that the geometric details of 3D meshes often exhibit similar local\\npatterns even across different shapes, and thus can be effectively represented\\nwith a shared learned generative space. We learn this space using a\\nsubdivision-based encoder-decoder architecture trained in advance on a large\\ncollection of surfaces. We further observe that additional residual features\\ncan be transmitted progressively between intermediate levels of subdivision\\nthat enable the client to control the tradeoff between bandwidth cost and\\nquality of reconstruction, providing a neural progressive mesh representation.\\nWe evaluate our method on a diverse set of complex 3D shapes and demonstrate\\nthat it outperforms baselines in terms of compression ratio and reconstruction\\nquality.',\n",
       "       'In this paper, we develop a new method to automatically convert 2D line\\ndrawings from three orthographic views into 3D CAD models. Existing methods for\\nthis problem reconstruct 3D models by back-projecting the 2D observations into\\n3D space while maintaining explicit correspondence between the input and\\noutput. Such methods are sensitive to errors and noises in the input, thus\\noften fail in practice where the input drawings created by human designers are\\nimperfect. To overcome this difficulty, we leverage the attention mechanism in\\na Transformer-based sequence generation model to learn flexible mappings\\nbetween the input and output. Further, we design shape programs which are\\nsuitable for generating the objects of interest to boost the reconstruction\\naccuracy and facilitate CAD modeling applications. Experiments on a new\\nbenchmark dataset show that our method significantly outperforms existing ones\\nwhen the inputs are noisy or incomplete.',\n",
       "       'In this work we present a novel optimization strategy for image\\nreconstruction tasks under analysis-based image regularization, which promotes\\nsparse and/or low-rank solutions in some learned transform domain. We\\nparameterize such regularizers using potential functions that correspond to\\nweighted extensions of the $\\\\ell_p^p$-vector and $\\\\mathcal{S}_p^p$\\nSchatten-matrix quasi-norms with $0 < p \\\\le 1$. Our proposed minimization\\nstrategy extends the Iteratively Reweighted Least Squares (IRLS) method,\\ntypically used for synthesis-based $\\\\ell_p$ and $\\\\mathcal{S}_p$ norm and\\nanalysis-based $\\\\ell_1$ and nuclear norm regularization. We prove that under\\nmild conditions our minimization algorithm converges linearly to a stationary\\npoint, and we provide an upper bound for its convergence rate. Further, to\\nselect the parameters of the regularizers that deliver the best results for the\\nproblem at hand, we propose to learn them from training data by formulating the\\nsupervised learning process as a stochastic bilevel optimization problem. We\\nshow that thanks to the convergence guarantees of our proposed minimization\\nstrategy, such optimization can be successfully performed with a\\nmemory-efficient implicit back-propagation scheme. We implement our learned\\nIRLS variants as recurrent networks and assess their performance on the\\nchallenging image reconstruction tasks of non-blind deblurring,\\nsuper-resolution and demosaicking. The comparisons against other existing\\nlearned reconstruction approaches demonstrate that our overall method is very\\ncompetitive and in many cases outperforms existing unrolled networks, whose\\nnumber of parameters is orders of magnitude higher than in our case.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from arxiv_article_classifier.data.make_processed_data_bow import (\n",
    "    LATEX_REGEX,\n",
    "    LINEBREAK_REGEX,\n",
    "    NLP,\n",
    "    PUNCTUATION_DELETION_TABLE,\n",
    "    STOPLIST,\n",
    "    delete_regular_expression,\n",
    "    lemmatize_document,\n",
    "    remove_stopwords,\n",
    ")\n",
    "\n",
    "\n",
    "linebreak_cleaner = FunctionTransformer(\n",
    "    lambda X: np.array([delete_regular_expression(x, LINEBREAK_REGEX) for x in X])\n",
    ")\n",
    "\n",
    "lower_case_converter = FunctionTransformer(lambda X: np.array([x.lower() for x in X]))\n",
    "whitespace_deleter = FunctionTransformer(lambda X: np.array([\" \".join(x.split()) for x in X]))\n",
    "\n",
    "lemmatizer = FunctionTransformer(lambda X: np.array([lemmatize_document(x, NLP) for x in X]))\n",
    "\n",
    "punctuation_deleter = FunctionTransformer(\n",
    "    lambda X: np.array([x.translate(PUNCTUATION_DELETION_TABLE) for x in X])\n",
    ")\n",
    "\n",
    "stopword_remover = FunctionTransformer(\n",
    "    lambda X: np.array([remove_stopwords(x, STOPLIST) for x in X])\n",
    ")\n",
    "\n",
    "latex_remover = FunctionTransformer(\n",
    "    lambda X: np.array([delete_regular_expression(x, LATEX_REGEX) for x in X])\n",
    ")\n",
    "\n",
    "cleaning_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"clean_linebreaks\", linebreak_cleaner),\n",
    "        (\"remove_latex\", latex_remover),\n",
    "        (\"lemmatize\", lemmatizer),\n",
    "        (\"convert_to_lowercase\", lower_case_converter),\n",
    "        (\"delete_punctuation\", punctuation_deleter),\n",
    "        (\"delete_whitespace\", whitespace_deleter),\n",
    "        (\"remove_stopwords\", stopword_remover),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = cleaning_pipeline.transform(X_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "variable=count<br>nwords=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "count",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "count",
         "offsetgroup": "count",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          111,
          130,
          100,
          101,
          95,
          97,
          89,
          96,
          106,
          98,
          110,
          93,
          90,
          102,
          113,
          94,
          99,
          108,
          120,
          123,
          119,
          125,
          104,
          105,
          86,
          91,
          92,
          103,
          117,
          109,
          129,
          126,
          118,
          115,
          107,
          114,
          133,
          116,
          112,
          127,
          87,
          121,
          122,
          132,
          85,
          137,
          84,
          135,
          128,
          124,
          139,
          143,
          83,
          131,
          144,
          88,
          145,
          81,
          138,
          76,
          136,
          77,
          73,
          141,
          140,
          79,
          146,
          82,
          75,
          142,
          134,
          151,
          148,
          78,
          154,
          152,
          80,
          150,
          70,
          67,
          68,
          159,
          69,
          149,
          157,
          155,
          153,
          171,
          162,
          61,
          65,
          158,
          72,
          170,
          66,
          167,
          156,
          74,
          71,
          58,
          168,
          169,
          161,
          62,
          172,
          63,
          164,
          166,
          147,
          60,
          56,
          177,
          160,
          165,
          51,
          176,
          174,
          64,
          54,
          163,
          59,
          55,
          52,
          53,
          57,
          175,
          173,
          48,
          182,
          179,
          49,
          178,
          184,
          44,
          41,
          47,
          180,
          185,
          50,
          186,
          42,
          43,
          181,
          45,
          183,
          46,
          35,
          191,
          39,
          40,
          189,
          187,
          190,
          26,
          36,
          188,
          27,
          194,
          29,
          38,
          37,
          32,
          192,
          195,
          23,
          24,
          31,
          33,
          197,
          25,
          30,
          200,
          193,
          34,
          19,
          199,
          207,
          28,
          16,
          201,
          198,
          11,
          205,
          14,
          7,
          17,
          20,
          18,
          213,
          22,
          203,
          15,
          13,
          206,
          210
         ],
         "xaxis": "x",
         "y": [
          107,
          101,
          98,
          98,
          97,
          96,
          96,
          96,
          92,
          92,
          92,
          91,
          90,
          90,
          89,
          89,
          87,
          86,
          86,
          85,
          84,
          84,
          84,
          84,
          84,
          84,
          84,
          84,
          83,
          83,
          82,
          82,
          82,
          81,
          81,
          81,
          81,
          80,
          80,
          79,
          78,
          76,
          72,
          71,
          70,
          70,
          70,
          68,
          68,
          66,
          65,
          64,
          64,
          62,
          62,
          62,
          62,
          62,
          61,
          61,
          61,
          61,
          60,
          59,
          59,
          58,
          58,
          56,
          56,
          55,
          55,
          54,
          54,
          53,
          51,
          50,
          48,
          48,
          47,
          46,
          46,
          45,
          45,
          44,
          43,
          43,
          41,
          41,
          40,
          39,
          39,
          38,
          38,
          38,
          36,
          36,
          35,
          35,
          35,
          34,
          34,
          33,
          33,
          33,
          32,
          32,
          32,
          31,
          30,
          29,
          29,
          29,
          29,
          28,
          28,
          27,
          27,
          25,
          24,
          24,
          23,
          22,
          22,
          22,
          22,
          22,
          22,
          21,
          20,
          19,
          19,
          19,
          17,
          16,
          16,
          16,
          15,
          15,
          14,
          13,
          13,
          13,
          13,
          12,
          12,
          11,
          11,
          10,
          10,
          9,
          9,
          8,
          8,
          8,
          7,
          6,
          6,
          6,
          6,
          6,
          5,
          5,
          5,
          4,
          4,
          4,
          4,
          4,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          2,
          2,
          2,
          2,
          2,
          2,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "nwords"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "abstracts = (\n",
    "    pd.DataFrame(y_train, columns=labels)\n",
    "    .assign(abstract=X_train)\n",
    "    .assign(nwords=lambda df: df[\"abstract\"].map(lambda abstract: len(abstract.split())))\n",
    ")\n",
    "\n",
    "px.bar(abstracts[\"nwords\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abstracts have between 7 and 213 words after stop-word removal and the distribution does not show any obvious outliers. Let's have a quick look at both ends if they look reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>paper show initial stage development first principle formal logic characterise explore issue broadly define idea veracity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>summarize dynamic behavioral interaction introduce possible node embed base solution question temporal egonet subgraph transition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>short note establish positionality mean payoff game infinite game graph construct well found monotone universal graph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658</th>\n",
       "      <td>present optimal transport framework perform regression covariate response probability distribution compact euclidean subset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2549</th>\n",
       "      <td>introduce explicit family good interpolation point interpolation triangle may use either polynomial interpolation certain rational interpolation give explicit formula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2580</th>\n",
       "      <td>propose ziv zakai type low bound bayesian error estimate parameter betatheta mathbb r parameter space general need linear function</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4213</th>\n",
       "      <td>paper prove dalembert lagrange principle point masse use lagrange mach mechanical construction yield weighted balancing condition unit vector</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4296</th>\n",
       "      <td>prove coefficient sum square entry symmetric matrix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4483</th>\n",
       "      <td>standard fractional projection extend binary two mode network weight two mode network interesting property extended projection prove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5622</th>\n",
       "      <td>effectiveness compression text classification gzip recently garner lot attention note show bag word approach achieve similar well result efficient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7017</th>\n",
       "      <td>paper state condition controllability discrete time linear system case lie group finite semisimple center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7150</th>\n",
       "      <td>image deraining challenging task involve restore degraded image affect rain streak</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                    abstract\n",
       "402                                                paper show initial stage development first principle formal logic characterise explore issue broadly define idea veracity\n",
       "755                                        summarize dynamic behavioral interaction introduce possible node embed base solution question temporal egonet subgraph transition\n",
       "1033                                                   short note establish positionality mean payoff game infinite game graph construct well found monotone universal graph\n",
       "1658                                             present optimal transport framework perform regression covariate response probability distribution compact euclidean subset\n",
       "2549  introduce explicit family good interpolation point interpolation triangle may use either polynomial interpolation certain rational interpolation give explicit formula\n",
       "2580                                      propose ziv zakai type low bound bayesian error estimate parameter betatheta mathbb r parameter space general need linear function\n",
       "4213                           paper prove dalembert lagrange principle point masse use lagrange mach mechanical construction yield weighted balancing condition unit vector\n",
       "4296                                                                                                                     prove coefficient sum square entry symmetric matrix\n",
       "4483                                    standard fractional projection extend binary two mode network weight two mode network interesting property extended projection prove\n",
       "5622                      effectiveness compression text classification gzip recently garner lot attention note show bag word approach achieve similar well result efficient\n",
       "7017                                                               paper state condition controllability discrete time linear system case lie group finite semisimple center\n",
       "7150                                                                                      image deraining challenging task involve restore degraded image affect rain streak"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "abstracts[abstracts[\"nwords\"] < 20][[\"abstract\"]].display_fully()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>paper consider partial gathering problem mobile agent synchronous dynamic bidirectional ring network k agent distribute network partial gathering problem require give positive integer g k agent terminate configuration either least g agent agent exist node far partial gathering problem consider static graph paper start consider partial gathering dynamic graph first step consider problem 1 interval connect ring one link ring may miss time step network focus relationship value k g fully characterize solvability partial gathering problem analyze move complexity propose algorithm problem solve first show g partial gathering problem unsolvable k 2 g second show problem solve log g time total number ogn log g move 2 g 1 k 3 g 2 third show problem solve time total number okn move 3 g 1 k 8 g 4 notice since k og hold 3 g 1 k 8 g 4 move complexity okn case represent also ogn finally show problem solve time total number ogn move k 8 g 3 result mean partial gathering problem solve also dynamic ring k 2 g 1 addition agent require total number omegagn move solve partial resp total gathering problem thus k 3 g 1 agent solve partial gathering problem asymptotically optimal total number ogn move</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>paper integrate nonlinear manifold reduced order model nm roms domain decomposition dd nm roms approximate fom state nonlinear manifold train shallow sparse autoencoder use fom snapshot datum nm rom advantageous linear subspace roms ls roms problem slowly decay kolmogorov width however number nm rom parameter need train scale size fom moreover extreme scale problem storage high dimensional fom snapshot alone make rom training expensive alleviate training cost paper apply dd fom compute nm rom subdomain couple obtain global nm rom approach several advantage subdomain nm rom train parallel involve parameter train global nm rom require small subdomain fom dimensional training datum training subdomain nm rom tailor subdomain specific feature fom shallow sparse architecture autoencoder use subdomain nm rom allow application hyper reduction hr reduce complexity cause nonlinearity yield computational speedup nm rom paper provide first application nm rom hr dd problem particular detail algebraic dd formulation fom train nm rom hr subdomain develop sequential quadratic programming sqp solver evaluate coupled global nm rom theoretical convergence result sqp method priori posteriori error estimate dd nm rom hr provide propose dd nm rom hr approach numerically compare dd ls rom hr 2d steady state burgers equation show order magnitude improvement accuracy propose dd nm rom dd ls rom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2805</th>\n",
       "      <td>monte carlo mc sampling popular method estimate statistic eg expectation variance random variable slow convergence lead emergence advanced technique reduce variance mc estimator output computationally expensive solver control variate cv method correct mc estimator term derive auxiliary random variable highly correlate original random variable auxiliary variable may come surrogate model surrogate base cv strategy extend multilevel monte carlo mlmc framework rely sequence level correspond numerical simulator increase accuracy computational cost mlmc combine output sample obtain across level telescopic sum difference mc estimator successive fidelity paper introduce three multilevel variance reduction strategy rely surrogate base cv mlmc mlcv present extension cv correction term devise surrogate model simulator different level add mlmc cv improve mlmc estimator use cv base surrogate correction term level variance reduction achieve use surrogate base cv level mlmc mlcv strategy alternative solution reduce subset surrogate use multilevel estimation also introduce propose method test test case literature consist spectral discretization uncertain 1d heat equation statistic interest expect value integrate temperature along domain give time result assess term accuracy computational cost multilevel estimator depend whether construction surrogate associate computational cost precede evaluation estimator show low fidelity output strongly correlate high fidelity output significant variance reduction obtain use surrogate model coarser level also show take advantage pre existing surrogate model prove even efficient strategy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2824</th>\n",
       "      <td>hand gesture recognition base surface electromyographic semg signal promising approach develop human machine interfaces hmis natural control intuitive robot interface poly articulate prosthesis however real world application limit reliability problem due motion artefact postural temporal variability sensor positioning master thesis first application deep learning unibo inail dataset first public semg dataset explore variability subject session arm posture collect datum 8 session 7 able bodied subject execute 6 hand gesture 4 arm posture recent study address variability strategy base training set composition improve inter posture inter day generalization non deep machine learn classifier among rbf kernel svm yield high accuracy deep architecture realize work 1d cnn inspire 2d cnn report perform well public benchmark database 1d cnn various training strategy base training set composition implement test multi session training prove yield high inter session validation accuracy single session training two posture training prove good postural training prove benefit training one posture yield 812 inter posture test accuracy five day training prove good multi day training yield 759 inter day test accuracy result close baseline moreover result multi day training highlight phenomenon user adaptation indicate training also prioritize recent datum though well baseline achieve classification accuracy rightfully place 1d cnn among candidate research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4036</th>\n",
       "      <td>background mr base subchondral bone effectively predict knee osteoarthritis however clinical application limit cost time mr purpose aim develop novel distillation learning base method name srrd subchondral bone microstructural analysis use easily acquire ct image leverage pair mr image enhance ct base analysis model training material methods knee joint image ct mr modality collect october 2020 may 2021 firstly develop gan base generative model transform mr image ct image use establish anatomical correspondence two modality next obtain numerous patch subchondral bone region mr image together trabecular parameter bv tv tb th tb sp tb n correspond ct image patch via regression distillation learning technique use train regression model transfer mr structural information ct base model regress trabecular parameter far use knee osteoarthritis classification result total 80 participant evaluate ct base regression result trabecular parameter achieve intra class correlation coefficient iccs 0804 0773 0711 0622 bv tv tb th tb sp tb n respectively use distillation learning significantly improve performance ct base knee osteoarthritis classification method use cnn approach yield auc score 0767 95 ci 0681 0853 instead 0658 95 ci 0574 0742 p001 conclusion propose srrd method show high reliability validity mr ct registration regression knee osteoarthritis classification indicate feasibility subchondral bone microstructural analysis base ct image</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5063</th>\n",
       "      <td>present design textitin silico evaluation closed loop insulin delivery algorithm treat type 1 diabetes t1d consist data drive multi step ahead blood glucose bg predictor integrate linear time varying ltv model predictive control mpc framework instead identify open loop model glucoregulatory system available datum propose directly fit entire bg prediction predefine prediction horizon use mpc nonlinear function past input ouput datum affine function future insulin control input nonlinear part long short term memory lstm network propose affine component linear regression model choose assess benefit drawback compare traditional linear mpc base auto regressive exogenous arx input model identify datum evaluate propose lstm mpc controller three simulation scenario nominal case 3 meal per day random meal disturbance case meal generate recently publish meal generator case 25 decrease insulin sensitivity far scenario feedforward meal bolus administer challenging random meal generation scenario mean standard deviation percent time range 70 180 mg dl 7499 709 vs 5415 1489 mean standard deviation percent time tight range 70 140 mg dl 4778 855 vs 3462 904 mean standard deviation percent time sever hypoglycemia ie 54 mg dl 100 318 vs 945 1171 propose lstm mpc controller traditional arx mpc respectively approach provide accurate prediction future glucose concentration good closed loop performance overall mpc controller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5183</th>\n",
       "      <td>magnetic recording device still competitive storage density race solid state device thank new technology two dimensional magnetic recording tdmr advanced datum processing scheme need guarantee reliability tdmr datum pattern bit surround complementary bit four position manhattan distance tdmr grid call plus isolation pis pattern error prone recently introduce lexicographically order constrain loco code namely optimal plus loco op loco code prevent pattern write tdmr device however high density regime low energy regime additional error prone pattern emerge specifically datum pattern bit surround complementary bit three position manhattan distance call incomplete plus isolation ipis pattern paper present capacity achieve code forbid pis ipis pattern tdmr system wide read head collectively call pis ipis pattern rotate isolation rtis pattern call new code optimal loco ot loco code analyze ot loco code present simple encoding decode rule allow reconfigurability also present novel bridging idea code far increase rate simulation result demonstrate ot loco code capable eliminate medium noise effect entirely practical td density high rate far preserve storage capacity suggest use op loco code early device lifetime employ reconfiguration property switch ot loco code later point reconfiguration density energy axis decide manually moment next step use machine learning take decision base tdmr device status</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6841</th>\n",
       "      <td>open vocabulary segmentation challenging task require segmenting recognize object open set category one way address challenge leverage multi modal model clip provide image text feature share embed space bridge gap closed vocabulary open vocabulary recognition hence exist method often adopt two stage framework tackle problem input first go mask generator clip model along predict mask process involve extract feature image multiple time ineffective inefficient contrast propose build everything single stage framework use share frozen convolutional clip backbone significantly simplify current two stage pipeline also remarkably yield well accuracy cost trade propose fc clip benefit follow observation frozen clip backbone maintain ability open vocabulary classification also serve strong mask generator convolutional clip generalize well large input resolution one use contrastive image text pretraining train coco panoptic datum test zero shot manner fc clip achieve 268 pq 168 ap 341 miou ade20 k 182 pq 279 miou mapillary vistas 440 pq 268 ap 562 miou cityscapes outperform prior art 42 pq 24 ap 42 miou ade20 k 40 pq mapillary vistas 201 pq cityscapes respectively additionally training testing time fc clip 75x 66x significantly fast prior art use 59x parameter fc clip also set new state art performance across various open vocabulary semantic segmentation dataset code httpsgithubcombytedancefcclip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7817</th>\n",
       "      <td>background prostate cancer pc mri base risk calculator commonly base biological eg psa mri marker eg volume patient age whilst patient age measure amount year individual exist biological age ba might well reflect physiology individual however surrogate prostate mri linkage clinically significant pc cspc remain explore purpose obtain evaluate prostate age gap pag mri marker tool cspc risk study type retrospective population total 7243 prostate mri slice 468 participant undergo prostate biopsy deep learning model train 3223 mri slice crop around gland 81 low grade pc ncspc gleason score 6 131 negative case test remain 256 participant assessment chronological age define age participant time visit use train deep learning model predict age patient follow obtain pag define model predict age minus patient chronological age multivariate logistic regression model use estimate association odd ratio predictive value pag compare psa level pi rads3 statistical test test mann whitney u test permutation test roc curve analysis result multivariate adjust model show significant difference odd clinically significant pc cspc gleason score 7 378 95 confidence interval ci232 616 p 001 pag show well predictive ability compare pi rads3 adjust risk factor include psa level auc 0981 vs auc 0704 p001 conclusion pag significantly associate risk clinically significant pc outperform well establish pc risk factor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 abstract\n",
       "169                                                                                                                                                                                                                                                                                                                                                                                                                                                         paper consider partial gathering problem mobile agent synchronous dynamic bidirectional ring network k agent distribute network partial gathering problem require give positive integer g k agent terminate configuration either least g agent agent exist node far partial gathering problem consider static graph paper start consider partial gathering dynamic graph first step consider problem 1 interval connect ring one link ring may miss time step network focus relationship value k g fully characterize solvability partial gathering problem analyze move complexity propose algorithm problem solve first show g partial gathering problem unsolvable k 2 g second show problem solve log g time total number ogn log g move 2 g 1 k 3 g 2 third show problem solve time total number okn move 3 g 1 k 8 g 4 notice since k og hold 3 g 1 k 8 g 4 move complexity okn case represent also ogn finally show problem solve time total number ogn move k 8 g 3 result mean partial gathering problem solve also dynamic ring k 2 g 1 addition agent require total number omegagn move solve partial resp total gathering problem thus k 3 g 1 agent solve partial gathering problem asymptotically optimal total number ogn move\n",
       "1492                                                                                                                                                                                                                                                     paper integrate nonlinear manifold reduced order model nm roms domain decomposition dd nm roms approximate fom state nonlinear manifold train shallow sparse autoencoder use fom snapshot datum nm rom advantageous linear subspace roms ls roms problem slowly decay kolmogorov width however number nm rom parameter need train scale size fom moreover extreme scale problem storage high dimensional fom snapshot alone make rom training expensive alleviate training cost paper apply dd fom compute nm rom subdomain couple obtain global nm rom approach several advantage subdomain nm rom train parallel involve parameter train global nm rom require small subdomain fom dimensional training datum training subdomain nm rom tailor subdomain specific feature fom shallow sparse architecture autoencoder use subdomain nm rom allow application hyper reduction hr reduce complexity cause nonlinearity yield computational speedup nm rom paper provide first application nm rom hr dd problem particular detail algebraic dd formulation fom train nm rom hr subdomain develop sequential quadratic programming sqp solver evaluate coupled global nm rom theoretical convergence result sqp method priori posteriori error estimate dd nm rom hr provide propose dd nm rom hr approach numerically compare dd ls rom hr 2d steady state burgers equation show order magnitude improvement accuracy propose dd nm rom dd ls rom\n",
       "2805  monte carlo mc sampling popular method estimate statistic eg expectation variance random variable slow convergence lead emergence advanced technique reduce variance mc estimator output computationally expensive solver control variate cv method correct mc estimator term derive auxiliary random variable highly correlate original random variable auxiliary variable may come surrogate model surrogate base cv strategy extend multilevel monte carlo mlmc framework rely sequence level correspond numerical simulator increase accuracy computational cost mlmc combine output sample obtain across level telescopic sum difference mc estimator successive fidelity paper introduce three multilevel variance reduction strategy rely surrogate base cv mlmc mlcv present extension cv correction term devise surrogate model simulator different level add mlmc cv improve mlmc estimator use cv base surrogate correction term level variance reduction achieve use surrogate base cv level mlmc mlcv strategy alternative solution reduce subset surrogate use multilevel estimation also introduce propose method test test case literature consist spectral discretization uncertain 1d heat equation statistic interest expect value integrate temperature along domain give time result assess term accuracy computational cost multilevel estimator depend whether construction surrogate associate computational cost precede evaluation estimator show low fidelity output strongly correlate high fidelity output significant variance reduction obtain use surrogate model coarser level also show take advantage pre existing surrogate model prove even efficient strategy\n",
       "2824                                                                                                                                                                                  hand gesture recognition base surface electromyographic semg signal promising approach develop human machine interfaces hmis natural control intuitive robot interface poly articulate prosthesis however real world application limit reliability problem due motion artefact postural temporal variability sensor positioning master thesis first application deep learning unibo inail dataset first public semg dataset explore variability subject session arm posture collect datum 8 session 7 able bodied subject execute 6 hand gesture 4 arm posture recent study address variability strategy base training set composition improve inter posture inter day generalization non deep machine learn classifier among rbf kernel svm yield high accuracy deep architecture realize work 1d cnn inspire 2d cnn report perform well public benchmark database 1d cnn various training strategy base training set composition implement test multi session training prove yield high inter session validation accuracy single session training two posture training prove good postural training prove benefit training one posture yield 812 inter posture test accuracy five day training prove good multi day training yield 759 inter day test accuracy result close baseline moreover result multi day training highlight phenomenon user adaptation indicate training also prioritize recent datum though well baseline achieve classification accuracy rightfully place 1d cnn among candidate research\n",
       "4036                                                                                                                                                                                        background mr base subchondral bone effectively predict knee osteoarthritis however clinical application limit cost time mr purpose aim develop novel distillation learning base method name srrd subchondral bone microstructural analysis use easily acquire ct image leverage pair mr image enhance ct base analysis model training material methods knee joint image ct mr modality collect october 2020 may 2021 firstly develop gan base generative model transform mr image ct image use establish anatomical correspondence two modality next obtain numerous patch subchondral bone region mr image together trabecular parameter bv tv tb th tb sp tb n correspond ct image patch via regression distillation learning technique use train regression model transfer mr structural information ct base model regress trabecular parameter far use knee osteoarthritis classification result total 80 participant evaluate ct base regression result trabecular parameter achieve intra class correlation coefficient iccs 0804 0773 0711 0622 bv tv tb th tb sp tb n respectively use distillation learning significantly improve performance ct base knee osteoarthritis classification method use cnn approach yield auc score 0767 95 ci 0681 0853 instead 0658 95 ci 0574 0742 p001 conclusion propose srrd method show high reliability validity mr ct registration regression knee osteoarthritis classification indicate feasibility subchondral bone microstructural analysis base ct image\n",
       "5063                                                                                                                                                                                                                   present design textitin silico evaluation closed loop insulin delivery algorithm treat type 1 diabetes t1d consist data drive multi step ahead blood glucose bg predictor integrate linear time varying ltv model predictive control mpc framework instead identify open loop model glucoregulatory system available datum propose directly fit entire bg prediction predefine prediction horizon use mpc nonlinear function past input ouput datum affine function future insulin control input nonlinear part long short term memory lstm network propose affine component linear regression model choose assess benefit drawback compare traditional linear mpc base auto regressive exogenous arx input model identify datum evaluate propose lstm mpc controller three simulation scenario nominal case 3 meal per day random meal disturbance case meal generate recently publish meal generator case 25 decrease insulin sensitivity far scenario feedforward meal bolus administer challenging random meal generation scenario mean standard deviation percent time range 70 180 mg dl 7499 709 vs 5415 1489 mean standard deviation percent time tight range 70 140 mg dl 4778 855 vs 3462 904 mean standard deviation percent time sever hypoglycemia ie 54 mg dl 100 318 vs 945 1171 propose lstm mpc controller traditional arx mpc respectively approach provide accurate prediction future glucose concentration good closed loop performance overall mpc controller\n",
       "5183                                                                                                                                                                                                                              magnetic recording device still competitive storage density race solid state device thank new technology two dimensional magnetic recording tdmr advanced datum processing scheme need guarantee reliability tdmr datum pattern bit surround complementary bit four position manhattan distance tdmr grid call plus isolation pis pattern error prone recently introduce lexicographically order constrain loco code namely optimal plus loco op loco code prevent pattern write tdmr device however high density regime low energy regime additional error prone pattern emerge specifically datum pattern bit surround complementary bit three position manhattan distance call incomplete plus isolation ipis pattern paper present capacity achieve code forbid pis ipis pattern tdmr system wide read head collectively call pis ipis pattern rotate isolation rtis pattern call new code optimal loco ot loco code analyze ot loco code present simple encoding decode rule allow reconfigurability also present novel bridging idea code far increase rate simulation result demonstrate ot loco code capable eliminate medium noise effect entirely practical td density high rate far preserve storage capacity suggest use op loco code early device lifetime employ reconfiguration property switch ot loco code later point reconfiguration density energy axis decide manually moment next step use machine learning take decision base tdmr device status\n",
       "6841                                                                                                                                                                                                                                     open vocabulary segmentation challenging task require segmenting recognize object open set category one way address challenge leverage multi modal model clip provide image text feature share embed space bridge gap closed vocabulary open vocabulary recognition hence exist method often adopt two stage framework tackle problem input first go mask generator clip model along predict mask process involve extract feature image multiple time ineffective inefficient contrast propose build everything single stage framework use share frozen convolutional clip backbone significantly simplify current two stage pipeline also remarkably yield well accuracy cost trade propose fc clip benefit follow observation frozen clip backbone maintain ability open vocabulary classification also serve strong mask generator convolutional clip generalize well large input resolution one use contrastive image text pretraining train coco panoptic datum test zero shot manner fc clip achieve 268 pq 168 ap 341 miou ade20 k 182 pq 279 miou mapillary vistas 440 pq 268 ap 562 miou cityscapes outperform prior art 42 pq 24 ap 42 miou ade20 k 40 pq mapillary vistas 201 pq cityscapes respectively additionally training testing time fc clip 75x 66x significantly fast prior art use 59x parameter fc clip also set new state art performance across various open vocabulary semantic segmentation dataset code httpsgithubcombytedancefcclip\n",
       "7817                                                                                                                                                                                                                                       background prostate cancer pc mri base risk calculator commonly base biological eg psa mri marker eg volume patient age whilst patient age measure amount year individual exist biological age ba might well reflect physiology individual however surrogate prostate mri linkage clinically significant pc cspc remain explore purpose obtain evaluate prostate age gap pag mri marker tool cspc risk study type retrospective population total 7243 prostate mri slice 468 participant undergo prostate biopsy deep learning model train 3223 mri slice crop around gland 81 low grade pc ncspc gleason score 6 131 negative case test remain 256 participant assessment chronological age define age participant time visit use train deep learning model predict age patient follow obtain pag define model predict age minus patient chronological age multivariate logistic regression model use estimate association odd ratio predictive value pag compare psa level pi rads3 statistical test test mann whitney u test permutation test roc curve analysis result multivariate adjust model show significant difference odd clinically significant pc cspc gleason score 7 378 95 confidence interval ci232 616 p 001 pag show well predictive ability compare pi rads3 adjust risk factor include psa level auc 0981 vs auc 0704 p001 conclusion pag significantly associate risk clinically significant pc outperform well establish pc risk factor"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "abstracts[abstracts[\"nwords\"] > 200][[\"abstract\"]].display_fully()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks reasonable. Let's proceed to create the dataset and train our first baseline algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arxiv_article_classifier.data.make_processed_data_bow import convert_interim_to_processed_data\n",
    "datafolder_processed_bow = DATAFOLDER_PROCESSED/'bow-model'\n",
    "datafolder_processed_bow.mkdir(exist_ok=True)\n",
    "convert_interim_to_processed_data(DATAFOLDER_INTERIM, datafolder_processed_bow)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arxiv-article-classifier-IjPt3q2a-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
