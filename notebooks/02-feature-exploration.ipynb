{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 02 - Feature Exploration\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# --- Configture Notebook ------\n",
    "# show all outputs of cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import black\n",
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load(\n",
    "    lab=True,\n",
    "    line_length=100,\n",
    "    verbosity=\"DEBUG\",\n",
    "    target_version=black.TargetVersion.PY310,\n",
    ")\n",
    "\n",
    "# enable automatic reloading\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import plotly.express as px\n",
    "from sklearn.pipeline import FunctionTransformer, Pipeline\n",
    "from arxiv_article_classifier.data.load import load_processed_data\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from pandas.core.base import PandasObject\n",
    "from arxiv_article_classifier.utils import display_fully\n",
    "\n",
    "PandasObject.display_fully = display_fully\n",
    "\n",
    "DATAFOLDER = Path().cwd().parent / \"data\"\n",
    "FIGUREFOLDER = Path().cwd().parent / \"reports\" / \"figures\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "DATAFOLDER_INTERIM = Path().cwd().parent / \"data\" / \"interim\"\n",
    "DATAFOLDER_PROCESSED = Path().cwd().parent / \"data\" / \"processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_raw, _, _, y_train, _, _), labels = load_processed_data(DATAFOLDER_INTERIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['We focus on the problem of finding an optimal strategy for a team of two\\nplayers that faces an opponent in an imperfect-information zero-sum\\nextensive-form game. Team members are not allowed to communicate during play\\nbut can coordinate before the game. In that setting, it is known that the best\\nthe team can do is sample a profile of potentially randomized strategies (one\\nper player) from a joint (a.k.a. correlated) probability distribution at the\\nbeginning of the game. In this paper, we first provide new modeling results\\nabout computing such an optimal distribution by drawing a connection to a\\ndifferent literature on extensive-form correlation. Second, we provide an\\nalgorithm that computes such an optimal distribution by only using profiles\\nwhere only one of the team members gets to randomize in each profile. We can\\nalso cap the number of such profiles we allow in the solution. This begets an\\nanytime algorithm by increasing the cap. We find that often a handful of\\nwell-chosen such profiles suffices to reach optimal utility for the team. This\\nenables team members to reach coordination through a relatively simple and\\nunderstandable plan. Finally, inspired by this observation and leveraging\\ntheoretical concepts that we introduce, we develop an efficient\\ncolumn-generation algorithm for finding an optimal distribution for the team.\\nWe evaluate it on a suite of common benchmark games. It is three orders of\\nmagnitude faster than the prior state of the art on games that the latter can\\nsolve and it can also solve several games that were previously unsolvable.',\n",
       "       'We study a dynamic version of multi-agent path finding problem (called\\nD-MAPF) where existing agents may leave and new agents may join the team at\\ndifferent times. We introduce a new method to solve D-MAPF based on\\nconflict-resolution. The idea is, when a set of new agents joins the team and\\nthere are conflicts, instead of replanning for the whole team, to replan only\\nfor a minimal subset of agents whose plans conflict with each other. We utilize\\nanswer set programming as part of our method for planning, replanning and\\nidentifying minimal set of conflicts.',\n",
       "       'In this paper, we advocate Agent-Oriented Software Engi-neering (AOSE)\\nthrough employing Belief-Desire-Intention (BDI) intel-ligent agents for\\ndeveloping Sense-Compute-Control (SCC) applications in the Internet of Things\\nand Services (IoTS). We argue that not only the agent paradigm, in general, but\\nalso cognitive BDI agents with sense-deliberate-act cycle, in particular, fit\\nvery well to the nature of SCC applications in the IoTS. However, considering\\nthe highly constrained heterogeneous devices that are prevalent in the IoTS,\\nexisting BDI agent frameworks, even those especially created for Wireless\\nSensor Networks (WSNs), do not work. We elaborate on the challenges and propose\\npos-sible approaches to address them.',\n",
       "       ...,\n",
       "       'The recent proliferation of 3D content that can be consumed on hand-held\\ndevices necessitates efficient tools for transmitting large geometric data,\\ne.g., 3D meshes, over the Internet. Detailed high-resolution assets can pose a\\nchallenge to storage as well as transmission bandwidth, and level-of-detail\\ntechniques are often used to transmit an asset using an appropriate bandwidth\\nbudget. It is especially desirable for these methods to transmit data\\nprogressively, improving the quality of the geometry with more data. Our key\\ninsight is that the geometric details of 3D meshes often exhibit similar local\\npatterns even across different shapes, and thus can be effectively represented\\nwith a shared learned generative space. We learn this space using a\\nsubdivision-based encoder-decoder architecture trained in advance on a large\\ncollection of surfaces. We further observe that additional residual features\\ncan be transmitted progressively between intermediate levels of subdivision\\nthat enable the client to control the tradeoff between bandwidth cost and\\nquality of reconstruction, providing a neural progressive mesh representation.\\nWe evaluate our method on a diverse set of complex 3D shapes and demonstrate\\nthat it outperforms baselines in terms of compression ratio and reconstruction\\nquality.',\n",
       "       'In this paper, we develop a new method to automatically convert 2D line\\ndrawings from three orthographic views into 3D CAD models. Existing methods for\\nthis problem reconstruct 3D models by back-projecting the 2D observations into\\n3D space while maintaining explicit correspondence between the input and\\noutput. Such methods are sensitive to errors and noises in the input, thus\\noften fail in practice where the input drawings created by human designers are\\nimperfect. To overcome this difficulty, we leverage the attention mechanism in\\na Transformer-based sequence generation model to learn flexible mappings\\nbetween the input and output. Further, we design shape programs which are\\nsuitable for generating the objects of interest to boost the reconstruction\\naccuracy and facilitate CAD modeling applications. Experiments on a new\\nbenchmark dataset show that our method significantly outperforms existing ones\\nwhen the inputs are noisy or incomplete.',\n",
       "       'In this work we present a novel optimization strategy for image\\nreconstruction tasks under analysis-based image regularization, which promotes\\nsparse and/or low-rank solutions in some learned transform domain. We\\nparameterize such regularizers using potential functions that correspond to\\nweighted extensions of the $\\\\ell_p^p$-vector and $\\\\mathcal{S}_p^p$\\nSchatten-matrix quasi-norms with $0 < p \\\\le 1$. Our proposed minimization\\nstrategy extends the Iteratively Reweighted Least Squares (IRLS) method,\\ntypically used for synthesis-based $\\\\ell_p$ and $\\\\mathcal{S}_p$ norm and\\nanalysis-based $\\\\ell_1$ and nuclear norm regularization. We prove that under\\nmild conditions our minimization algorithm converges linearly to a stationary\\npoint, and we provide an upper bound for its convergence rate. Further, to\\nselect the parameters of the regularizers that deliver the best results for the\\nproblem at hand, we propose to learn them from training data by formulating the\\nsupervised learning process as a stochastic bilevel optimization problem. We\\nshow that thanks to the convergence guarantees of our proposed minimization\\nstrategy, such optimization can be successfully performed with a\\nmemory-efficient implicit back-propagation scheme. We implement our learned\\nIRLS variants as recurrent networks and assess their performance on the\\nchallenging image reconstruction tasks of non-blind deblurring,\\nsuper-resolution and demosaicking. The comparisons against other existing\\nlearned reconstruction approaches demonstrate that our overall method is very\\ncompetitive and in many cases outperforms existing unrolled networks, whose\\nnumber of parameters is orders of magnitude higher than in our case.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from arxiv_article_classifier.data.make_processed_data_tfidf import (\n",
    "    LATEX_REGEX,\n",
    "    LINEBREAK_REGEX,\n",
    "    NLP,\n",
    "    PUNCTUATION_DELETION_TABLE,\n",
    "    STOPLIST,\n",
    "    delete_regular_expression,\n",
    "    lemmatize_document,\n",
    "    remove_stopwords,\n",
    ")\n",
    "\n",
    "\n",
    "linebreak_cleaner = FunctionTransformer(\n",
    "    lambda X: np.array([delete_regular_expression(x, LINEBREAK_REGEX) for x in X])\n",
    ")\n",
    "\n",
    "lower_case_converter = FunctionTransformer(lambda X: np.array([x.lower() for x in X]))\n",
    "whitespace_deleter = FunctionTransformer(lambda X: np.array([\" \".join(x.split()) for x in X]))\n",
    "\n",
    "lemmatizer = FunctionTransformer(lambda X: np.array([lemmatize_document(x, NLP) for x in X]))\n",
    "\n",
    "punctuation_deleter = FunctionTransformer(\n",
    "    lambda X: np.array([x.translate(PUNCTUATION_DELETION_TABLE) for x in X])\n",
    ")\n",
    "\n",
    "stopword_remover = FunctionTransformer(\n",
    "    lambda X: np.array([remove_stopwords(x, STOPLIST) for x in X])\n",
    ")\n",
    "\n",
    "latex_remover = FunctionTransformer(\n",
    "    lambda X: np.array([delete_regular_expression(x, LATEX_REGEX) for x in X])\n",
    ")\n",
    "\n",
    "cleaning_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"clean_linebreaks\", linebreak_cleaner),\n",
    "        (\"remove_latex\", latex_remover),\n",
    "        (\"lemmatize\", lemmatizer),\n",
    "        (\"convert_to_lowercase\", lower_case_converter),\n",
    "        (\"delete_punctuation\", punctuation_deleter),\n",
    "        (\"delete_whitespace\", whitespace_deleter),\n",
    "        (\"remove_stopwords\", stopword_remover),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = cleaning_pipeline.transform(X_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "variable=count<br>nwords=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "count",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "count",
         "offsetgroup": "count",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          108,
          100,
          102,
          104,
          101,
          107,
          121,
          99,
          106,
          115,
          97,
          98,
          110,
          111,
          94,
          109,
          105,
          96,
          117,
          123,
          92,
          103,
          89,
          95,
          114,
          93,
          127,
          120,
          91,
          90,
          112,
          116,
          118,
          130,
          88,
          128,
          119,
          113,
          124,
          122,
          86,
          129,
          125,
          84,
          83,
          135,
          131,
          126,
          85,
          137,
          134,
          80,
          87,
          133,
          136,
          132,
          140,
          139,
          79,
          78,
          138,
          81,
          77,
          82,
          73,
          76,
          144,
          145,
          75,
          141,
          142,
          143,
          72,
          146,
          149,
          70,
          74,
          152,
          148,
          71,
          154,
          69,
          68,
          151,
          150,
          66,
          63,
          67,
          157,
          155,
          62,
          65,
          153,
          61,
          156,
          147,
          159,
          158,
          64,
          161,
          164,
          162,
          60,
          160,
          58,
          56,
          170,
          171,
          163,
          165,
          169,
          173,
          167,
          166,
          57,
          59,
          51,
          54,
          55,
          168,
          174,
          52,
          48,
          172,
          177,
          49,
          53,
          176,
          45,
          178,
          47,
          41,
          175,
          50,
          179,
          44,
          182,
          181,
          46,
          43,
          183,
          42,
          186,
          185,
          184,
          35,
          40,
          180,
          187,
          38,
          37,
          39,
          31,
          189,
          36,
          191,
          32,
          188,
          30,
          34,
          29,
          190,
          26,
          27,
          28,
          192,
          33,
          23,
          24,
          25,
          194,
          200,
          193,
          19,
          197,
          195,
          196,
          18,
          21,
          22,
          207,
          17,
          201,
          14,
          16,
          199,
          15,
          11,
          202,
          20,
          13,
          205,
          198,
          6,
          7,
          209,
          213,
          223,
          236,
          204,
          10,
          8,
          4,
          203,
          2,
          210
         ],
         "xaxis": "x",
         "y": [
          273,
          268,
          266,
          266,
          265,
          264,
          263,
          262,
          262,
          259,
          258,
          258,
          251,
          250,
          249,
          248,
          248,
          243,
          240,
          240,
          239,
          238,
          236,
          236,
          235,
          232,
          232,
          232,
          230,
          229,
          228,
          227,
          226,
          223,
          220,
          215,
          214,
          214,
          210,
          210,
          206,
          204,
          201,
          199,
          198,
          197,
          193,
          191,
          189,
          188,
          187,
          187,
          186,
          184,
          179,
          179,
          179,
          176,
          173,
          173,
          169,
          168,
          166,
          162,
          161,
          161,
          159,
          158,
          156,
          155,
          151,
          149,
          147,
          143,
          140,
          136,
          136,
          135,
          132,
          131,
          123,
          122,
          120,
          120,
          119,
          116,
          115,
          114,
          113,
          113,
          111,
          110,
          109,
          109,
          107,
          102,
          100,
          95,
          95,
          95,
          94,
          94,
          90,
          90,
          86,
          85,
          85,
          84,
          83,
          83,
          80,
          78,
          77,
          77,
          76,
          74,
          71,
          71,
          71,
          70,
          67,
          66,
          65,
          64,
          63,
          61,
          59,
          56,
          52,
          51,
          50,
          48,
          48,
          46,
          45,
          45,
          45,
          44,
          43,
          42,
          40,
          38,
          36,
          34,
          34,
          33,
          30,
          29,
          29,
          26,
          25,
          24,
          23,
          22,
          21,
          19,
          19,
          18,
          18,
          18,
          17,
          13,
          13,
          13,
          13,
          13,
          12,
          11,
          10,
          10,
          9,
          9,
          8,
          7,
          7,
          7,
          6,
          5,
          5,
          5,
          4,
          4,
          4,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          2,
          2,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Distribution of Word Count after Cleaning and Stopword Removal"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "nwords"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from arxiv_article_classifier.utils import save_image\n",
    "\n",
    "\n",
    "abstracts = (\n",
    "    pd.DataFrame(y_train, columns=labels)\n",
    "    .assign(abstract=X_train)\n",
    "    .assign(nwords=lambda df: df[\"abstract\"].map(lambda abstract: len(abstract.split())))\n",
    ")\n",
    "\n",
    "fig = px.bar(\n",
    "    abstracts[\"nwords\"].value_counts(),\n",
    "    title=\"Distribution of Word Count after Cleaning and Stopword Removal\",\n",
    ")\n",
    "save_image(fig, path=FIGUREFOLDER, filename=\"word-count-distribution-after-stopword-removal\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "236"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstracts[\"nwords\"].min()\n",
    "abstracts[\"nwords\"].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abstracts have between 2 and 236 words after stop-word removal and the distribution does not show any obvious outliers. Let's have a quick look at both ends if they look reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>paper show initial stage development first principle formal logic characterise explore issue broadly define idea veracity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>work consider estimation method sparse poisson model inspire 1 provide novel sign consistency result mild condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>short note establish positionality mean payoff game infinite game graph construct well found monotone universal graph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>note uncover three connection metric distortion problem voting method axiom social choice literature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>present optimal transport framework perform regression covariate response probability distribution compact euclidean subset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3318</th>\n",
       "      <td>paper argue synthetic datum produce differentially private generative model sufficiently anonymize therefore anonymous datum regulatory compliant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3932</th>\n",
       "      <td>paper prove dalembert lagrange principle point masse use lagrange mach mechanical construction yield weighted balancing condition unit vector</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4003</th>\n",
       "      <td>prove coefficient sum square entry symmetric matrix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>standard fractional projection extend binary two mode network weight two mode network interesting property extended projection prove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4700</th>\n",
       "      <td>work tackle problem online camera robot pose estimation single view successive frame image sequence crucial task robot interact world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6442</th>\n",
       "      <td>paper state condition controllability discrete time linear system case lie group finite semisimple center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6561</th>\n",
       "      <td>image deraining challenging task involve restore degraded image affect rain streak</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                               abstract\n",
       "406                           paper show initial stage development first principle formal logic characterise explore issue broadly define idea veracity\n",
       "745                                 work consider estimation method sparse poisson model inspire 1 provide novel sign consistency result mild condition\n",
       "1027                              short note establish positionality mean payoff game infinite game graph construct well found monotone universal graph\n",
       "1214                                               note uncover three connection metric distortion problem voting method axiom social choice literature\n",
       "1628                        present optimal transport framework perform regression covariate response probability distribution compact euclidean subset\n",
       "3318  paper argue synthetic datum produce differentially private generative model sufficiently anonymize therefore anonymous datum regulatory compliant\n",
       "3932      paper prove dalembert lagrange principle point masse use lagrange mach mechanical construction yield weighted balancing condition unit vector\n",
       "4003                                                                                                prove coefficient sum square entry symmetric matrix\n",
       "4176               standard fractional projection extend binary two mode network weight two mode network interesting property extended projection prove\n",
       "4700              work tackle problem online camera robot pose estimation single view successive frame image sequence crucial task robot interact world\n",
       "6442                                          paper state condition controllability discrete time linear system case lie group finite semisimple center\n",
       "6561                                                                 image deraining challenging task involve restore degraded image affect rain streak"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "abstracts[abstracts[\"nwords\"] < 20][[\"abstract\"]].display_fully()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>complexity increasingly tight coupling supply chain pose major logistical challenge lead company another challenge lead company -- pressure consumer critical public legislative measure supply chain law -- take responsibility supplier labour standard paper discuss new approach lead company use try address challenge algorithmic prediction business risk also environmental social risk describe technical cultural condition algorithmic prediction explain -- perspective lead company -- help address challenge develop scenario kind social consequence algorithmic prediction use lead company scenario derive policy option different stakeholder group help develop algorithmic prediction towards improve labour standard worker voice -- die komplexitat und zunehmend enge kopplung vieler lieferketten stellt eine grosse logistische herausforderung fur leitunternehmen dar eine weitere herausforderung besteht darin dass leitunternehmen -- gedrangt durch konsument innen eine kritische offentlichkeit und gesetzgeberische massnahman wie die lieferkettengesetze -- starker al bisher verantwortung fur arbeitsstandards ihren zulieferbetrieben ubernehmen mussen diesem beitrag diskutieren wir einen neuen ansatz mit dem leitunternehmen versuchen diese herausforderungen zu bearbeiten die algorithmische vorhersage von betriebswirtschaftlichen aber auch okologischen und sozialen risiken wir beschreiben die technischen und kulturellen bedingungen fur algorithmische vorhersage und erklaren wie diese -- aus perspektive von leitunternehmen -- bei der bearbeitung beider herausforderungen hilft anschliessend entwickeln wir szenarien wie und mit welchen sozialen konsequenzen algorithmische vorhersage durch leitunternehmen eingesetzt werden kann aus den szenarien leiten wir handlungsoptionen fur verschiedene stakeholder gruppen ab die dabei helfen sollen algorithmische vorhersage sinne einer verbesserung von arbeitsstandards und workers voice weiterzuentwickeln</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>paper integrate nonlinear manifold reduced order model nm roms domain decomposition dd nm roms approximate fom state nonlinear manifold train shallow sparse autoencoder use fom snapshot datum nm rom advantageous linear subspace roms ls roms problem slowly decay kolmogorov -width however number nm rom parameter need train scale size fom moreover extreme scale problem storage high dimensional fom snapshot alone make rom training expensive alleviate training cost paper apply dd fom compute nm rom subdomain couple obtain global nm rom approach several advantage subdomain nm rom train parallel involve parameter train global nm rom require small subdomain fom dimensional training datum training subdomain nm rom tailor subdomain specific feature fom shallow sparse architecture autoencoder use subdomain nm rom allow application hyper reduction hr reduce complexity cause nonlinearity yield computational speedup nm rom paper provide first application nm rom hr dd problem particular detail algebraic dd formulation fom train nm rom hr subdomain develop sequential quadratic programming sqp solver evaluate coupled global nm rom theoretical convergence result sqp method priori posteriori error estimate dd nm rom hr provide propose dd nm rom hr approach numerically compare dd ls rom hr 2d steady state burgers equation show order magnitude improvement accuracy propose dd nm rom dd ls rom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837</th>\n",
       "      <td>promising solution improve communication quality unmanned aerial vehicle uav widely integrate wireless network paper sake enhance message exchange rate user1 u1 user2 u2 intelligent reflective surface irs-and uav- assist two way amplify forward af relay wireless system propose u1 u2 communicate via uav mount irs af relay besides optimization problem maximize minimum rate cast variable namely af relay beamforme matrix irs phase shift two time slot need optimize achieve maximum rate low complexity alternately iterative ai scheme base zero forcing successive convex approximation lc zf sca algorithm put forward expression af relay beamforme matrix derive semi closed form zf method irs phase shift vector two time slot respectively optimize utilize sca algorithm obtain significant rate enhancement high performance ai method base one step semidefinite programming penalty sca ons sdp psca propose beamforme matrix af relay firstly solve singular value decomposition ons method irs phase shift matrix two time slot optimize sdp psca algorithm simulation result present rate performance propose lc zf sca ons sdp psca method surpass random phase af relay particular total transmit power equal 30dbm propose two method harvest 685 rate gain compare random phase af relay meanwhile rate performance ons sdp psca method cost extremely high complexity superior lc zf sca method</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2346</th>\n",
       "      <td>doctoral thesis develop new method set base state estimation active fault diagnosis afd nonlinear discrete time system ii discrete time nonlinear system whose trajectory satisfy nonlinear equality constraint call invariant iii linear descriptor system iv joint state parameter estimation nonlinear descriptor system set base estimation aim compute tight enclosure possible system state time step subject unknown bound uncertainty address issue present doctoral thesis propose new method efficiently propagate constrain zonotope czs nonlinear mapping besides thesis improve standard prediction update framework system invariant use new algorithm refine cz base nonlinear constraint addition thesis introduce new approach set base afd class nonlinear discrete time system affine parametrization reachable set obtain design optimal input set base afd addition thesis present new method base cz set value state estimation afd linear descriptor system linear static constraint state variable directly incorporate cz moreover thesis propose new representation unbounded set base zonotope allow develop method state estimation afd also unstable linear descriptor system without knowledge enclosure trajectory system thesis also develop new method set base joint state parameter estimation nonlinear descriptor system use cz unified framework lastly manuscript apply propose set base state estimation afd method use cz unmanned aerial vehicle water distribution network lithium ion cell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2670</th>\n",
       "      <td>hand gesture recognition base surface electromyographic semg signal promising approach develop human machine interfaces hmis natural control intuitive robot interface poly articulate prosthesis however real world application limit reliability problem due motion artefact postural temporal variability sensor positioning master thesis first application deep learning unibo inail dataset first public semg dataset explore variability subject session arm posture collect datum 8 session 7 able bodied subject execute 6 hand gesture 4 arm posture recent study address variability strategy base training set composition improve inter posture inter day generalization non deep machine learn classifier among rbf kernel svm yield high accuracy deep architecture realize work 1d cnn inspire 2d cnn report perform well public benchmark database 1d cnn various training strategy base training set composition implement test multi session training prove yield high inter session validation accuracy single session training two posture training prove good postural training prove benefit training one posture yield 812 inter posture test accuracy five day training prove good multi day training yield 759 inter day test accuracy result close baseline moreover result multi day training highlight phenomenon user adaptation indicate training also prioritize recent datum though well baseline achieve classification accuracy rightfully place 1d cnn among candidate research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3818</th>\n",
       "      <td>background estimation temporospatial clinical feature gait cf step count length step duration step frequency gait speed distance travel important component community base mobility evaluation use wearable accelerometer however challenge arise device complexity availability cost analytical methodology limit widespread application tool research question accelerometer datum commercially available smartphone use extract gait cf across broad range attainable gait velocity child duchenne muscular dystrophy dmd typically develop control td use machine learning ml-based method method fifteen child dmd 15 td underwent supervise clinical testing across range gait speed use 10 25 run walk 10mrw 25mrw 100 run walk 100mrw 6 minute walk 6mwt free walk fw evaluation wear mobile phone base accelerometer waist near body center mass gait cf extract accelerometer datum use multi step machine learning base process result compare ground truth observation datum result model prediction vs observed value step count distance travel step length show strong correlation pearson r -09929 09986 p00001 estimate demonstrate mean sd percentage error 149 704 step count 118 991 distance travel 037 752 step length compare ground truth observation combine 6mwt 100mrw fw task significance study finding indicate single accelerometer place near body center mass accurately measure cf across different gait speed td dmd peer suggest potential accurately measure cf community consumer level smartphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4693</th>\n",
       "      <td>present design textitin silico evaluation closed loop insulin delivery algorithm treat type 1 diabetes t1d consist data drive multi step ahead blood glucose bg predictor integrate linear time varying ltv model predictive control mpc framework instead identify open loop model glucoregulatory system available datum propose directly fit entire bg prediction predefine prediction horizon use mpc nonlinear function past input ouput datum affine function future insulin control input nonlinear part long short term memory lstm network propose affine component linear regression model choose assess benefit drawback compare traditional linear mpc base auto regressive exogenous arx input model identify datum evaluate propose lstm mpc controller three simulation scenario nominal case 3 meal per day random meal disturbance case meal generate recently publish meal generator case 25 decrease insulin sensitivity far scenario feedforward meal bolus administer challenging random meal generation scenario mean standard deviation percent time range 70 180 mg dl 7499 709 vs 5415 1489 mean standard deviation percent time tight range 70 140 mg dl 4778 855 vs 3462 904 mean standard deviation percent time sever hypoglycemia ie 54 mg dl 100 318 vs 945 1171 propose lstm mpc controller traditional arx mpc respectively approach provide accurate prediction future glucose concentration good closed loop performance overall mpc controller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4786</th>\n",
       "      <td>magnetic recording device still competitive storage density race solid state device thank new technology two dimensional magnetic recording tdmr advanced datum processing scheme need guarantee reliability tdmr datum pattern bit surround complementary bit four position manhattan distance tdmr grid call plus isolation pis pattern error prone recently introduce lexicographically order constrain loco code namely optimal plus loco op loco code prevent pattern write tdmr device however high density regime low energy regime additional error prone pattern emerge specifically datum pattern bit surround complementary bit three position manhattan distance call incomplete plus isolation ipis pattern paper present capacity achieve code forbid pis ipis pattern tdmr system wide read head collectively call pis ipis pattern rotate isolation rtis pattern call new code optimal loco ot loco code analyze ot loco code present simple encoding decode rule allow reconfigurability also present novel bridging idea code far increase rate simulation result demonstrate ot loco code capable eliminate medium noise effect entirely practical td density high rate far preserve storage capacity suggest use op loco code early device lifetime employ reconfiguration property switch ot loco code later point reconfiguration density energy axis decide manually moment next step use machine learning take decision base tdmr device status</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6295</th>\n",
       "      <td>open vocabulary segmentation challenging task require segmenting recognize object open set category one way address challenge leverage multi modal model clip provide image text feature share embed space bridge gap closed vocabulary open vocabulary recognition hence exist method often adopt two stage framework tackle problem input first go mask generator clip model along predict mask process involve extract feature image multiple time ineffective inefficient contrast propose build everything single stage framework use share frozen convolutional clip backbone significantly simplify current two stage pipeline also remarkably yield well accuracy cost trade propose fc clip benefit follow observation frozen clip backbone maintain ability open vocabulary classification also serve strong mask generator convolutional clip generalize well large input resolution one use contrastive image text pretraining train coco panoptic datum test zero shot manner fc clip achieve 268 pq 168 ap 341 miou ade20 k 182 pq 279 miou mapillary vistas 440 pq 268 ap 562 miou cityscapes outperform prior art 42 pq 24 ap 42 miou ade20 k 40 pq mapillary vistas 201 pq cityscapes respectively additionally training testing time fc clip 75x 66x significantly fast prior art use 59x parameter fc clip also set new state art performance across various open vocabulary semantic segmentation dataset code httpsgithubcombytedancefc-clip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7231</th>\n",
       "      <td>background prostate cancer pc mri base risk calculator commonly base biological eg psa mri marker eg volume patient age whilst patient age measure amount year individual exist biological age ba might well reflect physiology individual however surrogate prostate mri linkage clinically significant pc cspc remain explore purpose obtain evaluate prostate age gap pag mri marker tool cspc risk study type retrospective population total 7243 prostate mri slice 468 participant undergo prostate biopsy deep learning model train 3223 mri slice crop around gland 81 low grade pc ncspc gleason score 6 131 negative case test remain 256 participant assessment chronological age define age participant time visit use train deep learning model predict age patient follow obtain pag define model predict age minus patient chronological age multivariate logistic regression model use estimate association odd ratio predictive value pag compare psa level pi rads3 statistical test test mann whitney u test permutation test roc curve analysis result multivariate adjust model show significant difference odd clinically significant pc cspc gleason score 7 378 95 confidence interval ci232 616 p 001 pag show well predictive ability compare pi rads3 adjust risk factor include psa level auc 0981 vs auc 0704 p001 conclusion pag significantly associate risk clinically significant pc outperform well establish pc risk factor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               abstract\n",
       "1341  complexity increasingly tight coupling supply chain pose major logistical challenge lead company another challenge lead company -- pressure consumer critical public legislative measure supply chain law -- take responsibility supplier labour standard paper discuss new approach lead company use try address challenge algorithmic prediction business risk also environmental social risk describe technical cultural condition algorithmic prediction explain -- perspective lead company -- help address challenge develop scenario kind social consequence algorithmic prediction use lead company scenario derive policy option different stakeholder group help develop algorithmic prediction towards improve labour standard worker voice -- die komplexitat und zunehmend enge kopplung vieler lieferketten stellt eine grosse logistische herausforderung fur leitunternehmen dar eine weitere herausforderung besteht darin dass leitunternehmen -- gedrangt durch konsument innen eine kritische offentlichkeit und gesetzgeberische massnahman wie die lieferkettengesetze -- starker al bisher verantwortung fur arbeitsstandards ihren zulieferbetrieben ubernehmen mussen diesem beitrag diskutieren wir einen neuen ansatz mit dem leitunternehmen versuchen diese herausforderungen zu bearbeiten die algorithmische vorhersage von betriebswirtschaftlichen aber auch okologischen und sozialen risiken wir beschreiben die technischen und kulturellen bedingungen fur algorithmische vorhersage und erklaren wie diese -- aus perspektive von leitunternehmen -- bei der bearbeitung beider herausforderungen hilft anschliessend entwickeln wir szenarien wie und mit welchen sozialen konsequenzen algorithmische vorhersage durch leitunternehmen eingesetzt werden kann aus den szenarien leiten wir handlungsoptionen fur verschiedene stakeholder gruppen ab die dabei helfen sollen algorithmische vorhersage sinne einer verbesserung von arbeitsstandards und workers voice weiterzuentwickeln\n",
       "1483                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  paper integrate nonlinear manifold reduced order model nm roms domain decomposition dd nm roms approximate fom state nonlinear manifold train shallow sparse autoencoder use fom snapshot datum nm rom advantageous linear subspace roms ls roms problem slowly decay kolmogorov -width however number nm rom parameter need train scale size fom moreover extreme scale problem storage high dimensional fom snapshot alone make rom training expensive alleviate training cost paper apply dd fom compute nm rom subdomain couple obtain global nm rom approach several advantage subdomain nm rom train parallel involve parameter train global nm rom require small subdomain fom dimensional training datum training subdomain nm rom tailor subdomain specific feature fom shallow sparse architecture autoencoder use subdomain nm rom allow application hyper reduction hr reduce complexity cause nonlinearity yield computational speedup nm rom paper provide first application nm rom hr dd problem particular detail algebraic dd formulation fom train nm rom hr subdomain develop sequential quadratic programming sqp solver evaluate coupled global nm rom theoretical convergence result sqp method priori posteriori error estimate dd nm rom hr provide propose dd nm rom hr approach numerically compare dd ls rom hr 2d steady state burgers equation show order magnitude improvement accuracy propose dd nm rom dd ls rom\n",
       "1837                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   promising solution improve communication quality unmanned aerial vehicle uav widely integrate wireless network paper sake enhance message exchange rate user1 u1 user2 u2 intelligent reflective surface irs-and uav- assist two way amplify forward af relay wireless system propose u1 u2 communicate via uav mount irs af relay besides optimization problem maximize minimum rate cast variable namely af relay beamforme matrix irs phase shift two time slot need optimize achieve maximum rate low complexity alternately iterative ai scheme base zero forcing successive convex approximation lc zf sca algorithm put forward expression af relay beamforme matrix derive semi closed form zf method irs phase shift vector two time slot respectively optimize utilize sca algorithm obtain significant rate enhancement high performance ai method base one step semidefinite programming penalty sca ons sdp psca propose beamforme matrix af relay firstly solve singular value decomposition ons method irs phase shift matrix two time slot optimize sdp psca algorithm simulation result present rate performance propose lc zf sca ons sdp psca method surpass random phase af relay particular total transmit power equal 30dbm propose two method harvest 685 rate gain compare random phase af relay meanwhile rate performance ons sdp psca method cost extremely high complexity superior lc zf sca method\n",
       "2346                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             doctoral thesis develop new method set base state estimation active fault diagnosis afd nonlinear discrete time system ii discrete time nonlinear system whose trajectory satisfy nonlinear equality constraint call invariant iii linear descriptor system iv joint state parameter estimation nonlinear descriptor system set base estimation aim compute tight enclosure possible system state time step subject unknown bound uncertainty address issue present doctoral thesis propose new method efficiently propagate constrain zonotope czs nonlinear mapping besides thesis improve standard prediction update framework system invariant use new algorithm refine cz base nonlinear constraint addition thesis introduce new approach set base afd class nonlinear discrete time system affine parametrization reachable set obtain design optimal input set base afd addition thesis present new method base cz set value state estimation afd linear descriptor system linear static constraint state variable directly incorporate cz moreover thesis propose new representation unbounded set base zonotope allow develop method state estimation afd also unstable linear descriptor system without knowledge enclosure trajectory system thesis also develop new method set base joint state parameter estimation nonlinear descriptor system use cz unified framework lastly manuscript apply propose set base state estimation afd method use cz unmanned aerial vehicle water distribution network lithium ion cell\n",
       "2670                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                hand gesture recognition base surface electromyographic semg signal promising approach develop human machine interfaces hmis natural control intuitive robot interface poly articulate prosthesis however real world application limit reliability problem due motion artefact postural temporal variability sensor positioning master thesis first application deep learning unibo inail dataset first public semg dataset explore variability subject session arm posture collect datum 8 session 7 able bodied subject execute 6 hand gesture 4 arm posture recent study address variability strategy base training set composition improve inter posture inter day generalization non deep machine learn classifier among rbf kernel svm yield high accuracy deep architecture realize work 1d cnn inspire 2d cnn report perform well public benchmark database 1d cnn various training strategy base training set composition implement test multi session training prove yield high inter session validation accuracy single session training two posture training prove good postural training prove benefit training one posture yield 812 inter posture test accuracy five day training prove good multi day training yield 759 inter day test accuracy result close baseline moreover result multi day training highlight phenomenon user adaptation indicate training also prioritize recent datum though well baseline achieve classification accuracy rightfully place 1d cnn among candidate research\n",
       "3818                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           background estimation temporospatial clinical feature gait cf step count length step duration step frequency gait speed distance travel important component community base mobility evaluation use wearable accelerometer however challenge arise device complexity availability cost analytical methodology limit widespread application tool research question accelerometer datum commercially available smartphone use extract gait cf across broad range attainable gait velocity child duchenne muscular dystrophy dmd typically develop control td use machine learning ml-based method method fifteen child dmd 15 td underwent supervise clinical testing across range gait speed use 10 25 run walk 10mrw 25mrw 100 run walk 100mrw 6 minute walk 6mwt free walk fw evaluation wear mobile phone base accelerometer waist near body center mass gait cf extract accelerometer datum use multi step machine learning base process result compare ground truth observation datum result model prediction vs observed value step count distance travel step length show strong correlation pearson r -09929 09986 p00001 estimate demonstrate mean sd percentage error 149 704 step count 118 991 distance travel 037 752 step length compare ground truth observation combine 6mwt 100mrw fw task significance study finding indicate single accelerometer place near body center mass accurately measure cf across different gait speed td dmd peer suggest potential accurately measure cf community consumer level smartphone\n",
       "4693                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 present design textitin silico evaluation closed loop insulin delivery algorithm treat type 1 diabetes t1d consist data drive multi step ahead blood glucose bg predictor integrate linear time varying ltv model predictive control mpc framework instead identify open loop model glucoregulatory system available datum propose directly fit entire bg prediction predefine prediction horizon use mpc nonlinear function past input ouput datum affine function future insulin control input nonlinear part long short term memory lstm network propose affine component linear regression model choose assess benefit drawback compare traditional linear mpc base auto regressive exogenous arx input model identify datum evaluate propose lstm mpc controller three simulation scenario nominal case 3 meal per day random meal disturbance case meal generate recently publish meal generator case 25 decrease insulin sensitivity far scenario feedforward meal bolus administer challenging random meal generation scenario mean standard deviation percent time range 70 180 mg dl 7499 709 vs 5415 1489 mean standard deviation percent time tight range 70 140 mg dl 4778 855 vs 3462 904 mean standard deviation percent time sever hypoglycemia ie 54 mg dl 100 318 vs 945 1171 propose lstm mpc controller traditional arx mpc respectively approach provide accurate prediction future glucose concentration good closed loop performance overall mpc controller\n",
       "4786                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            magnetic recording device still competitive storage density race solid state device thank new technology two dimensional magnetic recording tdmr advanced datum processing scheme need guarantee reliability tdmr datum pattern bit surround complementary bit four position manhattan distance tdmr grid call plus isolation pis pattern error prone recently introduce lexicographically order constrain loco code namely optimal plus loco op loco code prevent pattern write tdmr device however high density regime low energy regime additional error prone pattern emerge specifically datum pattern bit surround complementary bit three position manhattan distance call incomplete plus isolation ipis pattern paper present capacity achieve code forbid pis ipis pattern tdmr system wide read head collectively call pis ipis pattern rotate isolation rtis pattern call new code optimal loco ot loco code analyze ot loco code present simple encoding decode rule allow reconfigurability also present novel bridging idea code far increase rate simulation result demonstrate ot loco code capable eliminate medium noise effect entirely practical td density high rate far preserve storage capacity suggest use op loco code early device lifetime employ reconfiguration property switch ot loco code later point reconfiguration density energy axis decide manually moment next step use machine learning take decision base tdmr device status\n",
       "6295                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  open vocabulary segmentation challenging task require segmenting recognize object open set category one way address challenge leverage multi modal model clip provide image text feature share embed space bridge gap closed vocabulary open vocabulary recognition hence exist method often adopt two stage framework tackle problem input first go mask generator clip model along predict mask process involve extract feature image multiple time ineffective inefficient contrast propose build everything single stage framework use share frozen convolutional clip backbone significantly simplify current two stage pipeline also remarkably yield well accuracy cost trade propose fc clip benefit follow observation frozen clip backbone maintain ability open vocabulary classification also serve strong mask generator convolutional clip generalize well large input resolution one use contrastive image text pretraining train coco panoptic datum test zero shot manner fc clip achieve 268 pq 168 ap 341 miou ade20 k 182 pq 279 miou mapillary vistas 440 pq 268 ap 562 miou cityscapes outperform prior art 42 pq 24 ap 42 miou ade20 k 40 pq mapillary vistas 201 pq cityscapes respectively additionally training testing time fc clip 75x 66x significantly fast prior art use 59x parameter fc clip also set new state art performance across various open vocabulary semantic segmentation dataset code httpsgithubcombytedancefc-clip\n",
       "7231                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     background prostate cancer pc mri base risk calculator commonly base biological eg psa mri marker eg volume patient age whilst patient age measure amount year individual exist biological age ba might well reflect physiology individual however surrogate prostate mri linkage clinically significant pc cspc remain explore purpose obtain evaluate prostate age gap pag mri marker tool cspc risk study type retrospective population total 7243 prostate mri slice 468 participant undergo prostate biopsy deep learning model train 3223 mri slice crop around gland 81 low grade pc ncspc gleason score 6 131 negative case test remain 256 participant assessment chronological age define age participant time visit use train deep learning model predict age patient follow obtain pag define model predict age minus patient chronological age multivariate logistic regression model use estimate association odd ratio predictive value pag compare psa level pi rads3 statistical test test mann whitney u test permutation test roc curve analysis result multivariate adjust model show significant difference odd clinically significant pc cspc gleason score 7 378 95 confidence interval ci232 616 p 001 pag show well predictive ability compare pi rads3 adjust risk factor include psa level auc 0981 vs auc 0704 p001 conclusion pag significantly associate risk clinically significant pc outperform well establish pc risk factor"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "abstracts[abstracts[\"nwords\"] > 200][[\"abstract\"]].display_fully()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks all reasonable apart from that one, which gives its abstract both in English and in German. Let's ignore this for now though and proceed to create the dataset and train our first baseline algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The complexity and increasingly tight coupling of supply chains poses a major\\nlogistical challenge for leading companies. Another challenge is that leading\\ncompanies -- under pressure from consumers, a critical public and legislative\\nmeasures such as supply chain laws -- have to take more responsibility than\\nbefore for their suppliers\\' labour standards. In this paper, we discuss a new\\napproach that leading companies are using to try to address these challenges:\\nalgorithmic prediction of business risks, but also environmental and social\\nrisks. We describe the technical and cultural conditions for algorithmic\\nprediction and explain how -- from the perspective of leading companies -- it\\nhelps to address both challenges. We then develop scenarios on how and with\\nwhat kind of social consequences algorithmic prediction can be used by leading\\ncompanies. From the scenarios, we derive policy options for different\\nstakeholder groups to help develop algorithmic prediction towards improving\\nlabour standards and worker voice.\\n  --\\n  Die Komplexit\\\\\"at und zunehmend enge Kopplung vieler Lieferketten stellt eine\\ngro{\\\\ss}e logistische Herausforderung f\\\\\"ur Leitunternehmen dar. Eine weitere\\nHerausforderung besteht darin, dass Leitunternehmen -- gedr\\\\\"angt durch\\nKonsument:innen, eine kritische \\\\\"Offentlichkeit und gesetzgeberische\\nMa{\\\\ss}nahmen wie die Lieferkettengesetze -- st\\\\\"arker als bisher Verantwortung\\nf\\\\\"ur Arbeitsstandards in ihren Zulieferbetrieben \\\\\"ubernehmen m\\\\\"ussen. In\\ndiesem Beitrag diskutieren wir einen neuen Ansatz, mit dem Leitunternehmen\\nversuchen, diese Herausforderungen zu bearbeiten: die algorithmische Vorhersage\\nvon betriebswirtschaftlichen, aber auch \\\\\"okologischen und sozialen Risiken.\\nWir beschreiben die technischen und kulturellen Bedingungen f\\\\\"ur\\nalgorithmische Vorhersage und erkl\\\\\"aren, wie diese -- aus Perspektive von\\nLeitunternehmen -- bei der Bearbeitung beider Herausforderungen hilft.\\nAnschlie{\\\\ss}end entwickeln wir Szenarien, wie und mit welchen sozialen\\nKonsequenzen algorithmische Vorhersage durch Leitunternehmen eingesetzt werden\\nkann. Aus den Szenarien leiten wir Handlungsoptionen f\\\\\"ur verschiedene\\nStakeholder-Gruppen ab, die dabei helfen sollen, algorithmische Vorhersage im\\nSinne einer Verbesserung von Arbeitsstandards und Workers\\' Voice\\nweiterzuentwickeln.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_raw[1341]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks reasonable. Let's proceed to create the dataset and train our first baseline algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the following code or use make processed-data instead\n",
    "\n",
    "# from arxiv_article_classifier.data.make_processed_data_bow import convert_interim_to_processed_data\n",
    "#\n",
    "# datafolder_processed_bow = DATAFOLDER_PROCESSED / \"bow-model\"\n",
    "# datafolder_processed_bow.mkdir(exist_ok=True)\n",
    "# convert_interim_to_processed_data(DATAFOLDER_INTERIM, datafolder_processed_bow)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arxiv-article-classifier-IjPt3q2a-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
