{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 03 - Creating a Simple Baseline Model\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# --- Configture Notebook ------\n",
    "# show all outputs of cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import black\n",
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load(\n",
    "    lab=True,\n",
    "    line_length=100,\n",
    "    verbosity=\"DEBUG\",\n",
    "    target_version=black.TargetVersion.PY310,\n",
    ")\n",
    "\n",
    "# enable automatic reloading\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from pandas.core.base import PandasObject\n",
    "from arxiv_article_classifier.utils import display_fully\n",
    "\n",
    "PandasObject.display_fully = display_fully\n",
    "\n",
    "DATAFOLDER = Path().cwd().parent / \"data\"\n",
    "DATAFOLDER_PROCESSED = DATAFOLDER / \"processed\" / \"bow-model\"\n",
    "\n",
    "from arxiv_article_classifier.data.load import load_processed_data, load_taxonomy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "(\n",
    "    (X_train, X_val, _, y_train, y_val, _),\n",
    "    labels,\n",
    ") = load_processed_data(DATAFOLDER_PROCESSED)\n",
    "\n",
    "# load taxonomy\n",
    "taxonomy = load_taxonomy(DATAFOLDER / \"raw\" / \"taxonomy.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cs.CL - Computation and Language\n",
      "----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('model', 2144),\n",
       " ('language', 1289),\n",
       " ('use', 942),\n",
       " ('task', 844),\n",
       " ('speech', 686),\n",
       " ('text', 651),\n",
       " ('datum', 620),\n",
       " ('base', 609),\n",
       " ('method', 608),\n",
       " ('propose', 595),\n",
       " ('dataset', 587),\n",
       " ('performance', 579),\n",
       " ('large', 512),\n",
       " ('result', 486),\n",
       " ('llm', 483)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cs.CV - Computer Vision and Pattern Recognition\n",
      "----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('model', 1495),\n",
       " ('image', 1309),\n",
       " ('method', 1171),\n",
       " ('propose', 935),\n",
       " ('dataset', 800),\n",
       " ('use', 760),\n",
       " ('base', 757),\n",
       " ('task', 625),\n",
       " ('datum', 624),\n",
       " ('feature', 597),\n",
       " ('performance', 560),\n",
       " ('result', 531),\n",
       " ('approach', 515),\n",
       " ('learning', 512),\n",
       " ('object', 490)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cs.CY - Computers and Society\n",
      "----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('model', 737),\n",
       " ('ai', 716),\n",
       " ('use', 703),\n",
       " ('datum', 495),\n",
       " ('study', 421),\n",
       " ('system', 398),\n",
       " ('paper', 359),\n",
       " ('base', 352),\n",
       " ('user', 345),\n",
       " ('research', 335),\n",
       " ('provide', 312),\n",
       " ('social', 306),\n",
       " ('result', 294),\n",
       " ('fairness', 291),\n",
       " ('propose', 283)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cs.GT - Computer Science and Game Theory\n",
      "----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('game', 969),\n",
       " ('agent', 834),\n",
       " ('model', 522),\n",
       " ('algorithm', 514),\n",
       " ('show', 491),\n",
       " ('problem', 476),\n",
       " ('equilibrium', 464),\n",
       " ('mechanism', 422),\n",
       " ('study', 382),\n",
       " ('strategy', 357),\n",
       " ('use', 339),\n",
       " ('result', 330),\n",
       " ('player', 326),\n",
       " ('propose', 306),\n",
       " ('base', 288)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cs.LG - Machine Learning\n",
      "----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('model', 3490),\n",
       " ('use', 1835),\n",
       " ('method', 1819),\n",
       " ('learning', 1728),\n",
       " ('propose', 1658),\n",
       " ('datum', 1595),\n",
       " ('base', 1400),\n",
       " ('algorithm', 1297),\n",
       " ('network', 1267),\n",
       " ('performance', 1132),\n",
       " ('approach', 1129),\n",
       " ('result', 1123),\n",
       " ('task', 1118),\n",
       " ('show', 1118),\n",
       " ('agent', 1022)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cs.MA - Multiagent Systems\n",
      "----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('agent', 1716),\n",
       " ('multi', 648),\n",
       " ('model', 540),\n",
       " ('propose', 516),\n",
       " ('algorithm', 491),\n",
       " ('learning', 483),\n",
       " ('base', 462),\n",
       " ('problem', 457),\n",
       " ('use', 453),\n",
       " ('system', 444),\n",
       " ('method', 415),\n",
       " ('policy', 361),\n",
       " ('task', 359),\n",
       " ('show', 349),\n",
       " ('environment', 330)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cs.RO - Robotics\n",
      "----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('robot', 1057),\n",
       " ('use', 767),\n",
       " ('model', 746),\n",
       " ('propose', 694),\n",
       " ('task', 669),\n",
       " ('method', 667),\n",
       " ('base', 633),\n",
       " ('system', 571),\n",
       " ('approach', 532),\n",
       " ('environment', 470),\n",
       " ('agent', 448),\n",
       " ('control', 411),\n",
       " ('algorithm', 402),\n",
       " ('object', 400),\n",
       " ('real', 399)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cs.SI - Social and Information Networks\n",
      "----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('network', 1032),\n",
       " ('graph', 933),\n",
       " ('model', 767),\n",
       " ('social', 624),\n",
       " ('use', 550),\n",
       " ('node', 450),\n",
       " ('user', 443),\n",
       " ('propose', 431),\n",
       " ('base', 399),\n",
       " ('method', 396),\n",
       " ('study', 389),\n",
       " ('datum', 366),\n",
       " ('information', 347),\n",
       " ('result', 327),\n",
       " ('community', 309)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eess.AS - Audio and Speech Processing\n",
      "----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('model', 1400),\n",
       " ('speech', 1228),\n",
       " ('use', 667),\n",
       " ('audio', 626),\n",
       " ('propose', 589),\n",
       " ('method', 478),\n",
       " ('performance', 444),\n",
       " ('base', 443),\n",
       " ('datum', 388),\n",
       " ('dataset', 387),\n",
       " ('system', 385),\n",
       " ('task', 382),\n",
       " ('language', 377),\n",
       " ('speaker', 368),\n",
       " ('result', 346)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eess.SP - Signal Processing\n",
      "----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('propose', 823),\n",
       " ('model', 622),\n",
       " ('base', 609),\n",
       " ('method', 558),\n",
       " ('use', 558),\n",
       " ('system', 536),\n",
       " ('signal', 534),\n",
       " ('performance', 468),\n",
       " ('network', 453),\n",
       " ('communication', 443),\n",
       " ('datum', 419),\n",
       " ('result', 415),\n",
       " ('algorithm', 408),\n",
       " ('channel', 369),\n",
       " ('paper', 348)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eess.SY - Systems and Control\n",
      "----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('system', 1042),\n",
       " ('control', 804),\n",
       " ('model', 772),\n",
       " ('propose', 766),\n",
       " ('use', 615),\n",
       " ('base', 586),\n",
       " ('method', 478),\n",
       " ('problem', 460),\n",
       " ('time', 459),\n",
       " ('approach', 431),\n",
       " ('paper', 430),\n",
       " ('algorithm', 400),\n",
       " ('result', 391),\n",
       " ('network', 387),\n",
       " ('state', 357)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "math.NA - Numerical Analysis\n",
      "----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('method', 1125),\n",
       " ('problem', 666),\n",
       " ('numerical', 556),\n",
       " ('use', 523),\n",
       " ('equation', 522),\n",
       " ('model', 477),\n",
       " ('propose', 441),\n",
       " ('solution', 432),\n",
       " ('order', 410),\n",
       " ('time', 394),\n",
       " ('result', 357),\n",
       " ('base', 340),\n",
       " ('system', 331),\n",
       " ('approach', 330),\n",
       " ('scheme', 325)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "math.OC - Optimization and Control\n",
      "----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('problem', 1085),\n",
       " ('algorithm', 681),\n",
       " ('method', 615),\n",
       " ('optimization', 567),\n",
       " ('propose', 513),\n",
       " ('model', 497),\n",
       " ('function', 483),\n",
       " ('use', 477),\n",
       " ('system', 438),\n",
       " ('control', 431),\n",
       " ('time', 421),\n",
       " ('optimal', 419),\n",
       " ('result', 418),\n",
       " ('show', 384),\n",
       " ('paper', 359)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "math.ST - Statistics Theory\n",
      "----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('model', 655),\n",
       " ('estimator', 471),\n",
       " ('distribution', 442),\n",
       " ('datum', 404),\n",
       " ('method', 388),\n",
       " ('result', 387),\n",
       " ('use', 362),\n",
       " ('function', 351),\n",
       " ('show', 348),\n",
       " ('sample', 347),\n",
       " ('problem', 345),\n",
       " ('propose', 337),\n",
       " ('algorithm', 308),\n",
       " ('study', 306),\n",
       " ('base', 293)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find top 15 most common words for each label\n",
    "top_n = 15\n",
    "common_words = {}\n",
    "\n",
    "for index, label in enumerate(labels):\n",
    "    print(f\"{label} - {taxonomy[label]}\")\n",
    "    print(\"----\")\n",
    "\n",
    "    most_common_word_counter = Counter(\n",
    "        [word for abstract in X_train[y_train.T[index].astype(\"bool\")] for word in abstract.split()]\n",
    "    ).most_common(top_n)\n",
    "    most_common_word_counter\n",
    "    common_words[label] = set(pair[0] for pair in most_common_word_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cs.CL - Computation and Language\n",
      "{'large', 'text', 'llm'}\n",
      "cs.CV - Computer Vision and Pattern Recognition\n",
      "{'feature', 'image'}\n",
      "cs.CY - Computers and Society\n",
      "{'fairness', 'research', 'ai', 'provide'}\n",
      "cs.GT - Computer Science and Game Theory\n",
      "{'mechanism', 'strategy', 'equilibrium', 'player', 'game'}\n",
      "cs.LG - Machine Learning\n",
      "set()\n",
      "cs.MA - Multiagent Systems\n",
      "{'policy', 'multi'}\n",
      "cs.RO - Robotics\n",
      "{'real', 'robot'}\n",
      "cs.SI - Social and Information Networks\n",
      "{'community', 'node', 'information', 'graph'}\n",
      "eess.AS - Audio and Speech Processing\n",
      "{'audio', 'speaker'}\n",
      "eess.SP - Signal Processing\n",
      "{'communication', 'signal', 'channel'}\n",
      "eess.SY - Systems and Control\n",
      "{'state'}\n",
      "math.NA - Numerical Analysis\n",
      "{'scheme', 'solution', 'numerical', 'order', 'equation'}\n",
      "math.OC - Optimization and Control\n",
      "{'optimal', 'optimization'}\n",
      "math.ST - Statistics Theory\n",
      "{'sample', 'estimator', 'distribution'}\n"
     ]
    }
   ],
   "source": [
    "for label in labels:\n",
    "    print(f\"{label} - {taxonomy[label]}\")\n",
    "    base_vocab = common_words[label]\n",
    "    for k, v in common_words.items():\n",
    "        if k != label:\n",
    "            base_vocab = base_vocab - v\n",
    "    print(base_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_keywords = {\n",
      "'cs.CL':\n",
      "{'large', 'text', 'llm'}\n",
      ",\n",
      "'cs.CV':\n",
      "{'feature', 'image'}\n",
      ",\n",
      "'cs.CY':\n",
      "{'fairness', 'research', 'ai', 'provide'}\n",
      ",\n",
      "'cs.GT':\n",
      "{'mechanism', 'strategy', 'equilibrium', 'player', 'game'}\n",
      ",\n",
      "'cs.LG':\n",
      "set()\n",
      ",\n",
      "'cs.MA':\n",
      "{'policy', 'multi'}\n",
      ",\n",
      "'cs.RO':\n",
      "{'real', 'robot'}\n",
      ",\n",
      "'cs.SI':\n",
      "{'community', 'node', 'information', 'graph'}\n",
      ",\n",
      "'eess.AS':\n",
      "{'audio', 'speaker'}\n",
      ",\n",
      "'eess.SP':\n",
      "{'communication', 'signal', 'channel'}\n",
      ",\n",
      "'eess.SY':\n",
      "{'state'}\n",
      ",\n",
      "'math.NA':\n",
      "{'scheme', 'solution', 'numerical', 'order', 'equation'}\n",
      ",\n",
      "'math.OC':\n",
      "{'optimal', 'optimization'}\n",
      ",\n",
      "'math.ST':\n",
      "{'sample', 'estimator', 'distribution'}\n",
      ",\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"label_keywords = {\")\n",
    "for label in labels:\n",
    "    print(f\"'{label}':\")\n",
    "    base_vocab = common_words[label]\n",
    "    for k, v in common_words.items():\n",
    "        if k != label:\n",
    "            base_vocab = base_vocab - v\n",
    "    print(base_vocab)\n",
    "    print(\",\")\n",
    "print(\"}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/walkenho/.cache/pypoetry/virtualenvs/arxiv-article-classifier-IjPt3q2a-py3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.62      0.41       886\n",
      "           1       0.40      0.69      0.51       817\n",
      "           2       0.16      0.69      0.26       661\n",
      "           3       0.27      0.72      0.39       607\n",
      "           4       0.53      0.50      0.51      1990\n",
      "           5       0.25      0.61      0.35       600\n",
      "           6       0.32      0.66      0.43       726\n",
      "           7       0.20      0.68      0.30       612\n",
      "           8       0.91      0.51      0.65       601\n",
      "           9       0.39      0.64      0.48       634\n",
      "          10       0.13      0.29      0.18       686\n",
      "          11       0.20      0.86      0.33       611\n",
      "          12       0.28      0.59      0.38       710\n",
      "          13       0.27      0.68      0.38       603\n",
      "\n",
      "   micro avg       0.28      0.61      0.38     10744\n",
      "   macro avg       0.33      0.62      0.40     10744\n",
      "weighted avg       0.35      0.61      0.41     10744\n",
      " samples avg       0.31      0.63      0.38     10744\n",
      "\n",
      "Performance on Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.62      0.42       296\n",
      "           1       0.40      0.66      0.50       273\n",
      "           2       0.16      0.70      0.26       220\n",
      "           3       0.29      0.71      0.41       203\n",
      "           4       0.54      0.51      0.52       664\n",
      "           5       0.24      0.59      0.34       200\n",
      "           6       0.32      0.65      0.43       242\n",
      "           7       0.20      0.71      0.32       204\n",
      "           8       0.93      0.51      0.66       201\n",
      "           9       0.37      0.62      0.46       211\n",
      "          10       0.13      0.28      0.17       229\n",
      "          11       0.19      0.83      0.31       203\n",
      "          12       0.28      0.59      0.38       237\n",
      "          13       0.27      0.68      0.38       201\n",
      "\n",
      "   micro avg       0.28      0.60      0.38      3584\n",
      "   macro avg       0.33      0.62      0.40      3584\n",
      "weighted avg       0.35      0.60      0.41      3584\n",
      " samples avg       0.31      0.63      0.39      3584\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/walkenho/.cache/pypoetry/virtualenvs/arxiv-article-classifier-IjPt3q2a-py3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Define the keywords you want to use for each label\n",
    "from sklearn.metrics import classification_report\n",
    "from arxiv_article_classifier.model.baseline import DictionaryModel\n",
    "\n",
    "\n",
    "label_keywords = {\n",
    "    \"cs.CL\": {\"large\", \"text\", \"llm\"},\n",
    "    \"cs.CV\": {\"feature\", \"image\"},\n",
    "    \"cs.CY\": {\"fairness\", \"research\", \"ai\", \"provide\"},\n",
    "    \"cs.GT\": {\"mechanism\", \"strategy\", \"equilibrium\", \"player\", \"game\"},\n",
    "    \"cs.LG\": {\"learning\"},\n",
    "    \"cs.MA\": {\"policy\", \"multi\"},\n",
    "    \"cs.RO\": {\"real\", \"robot\"},\n",
    "    \"cs.SI\": {\"community\", \"node\", \"information\", \"graph\"},\n",
    "    \"eess.AS\": {\"audio\", \"speaker\"},\n",
    "    \"eess.SP\": {\"communication\", \"signal\", \"channel\"},\n",
    "    \"eess.SY\": {\"state\"},\n",
    "    \"math.NA\": {\"scheme\", \"solution\", \"numerical\", \"order\", \"equation\"},\n",
    "    \"math.OC\": {\"optimal\", \"optimization\"},\n",
    "    \"math.ST\": {\"sample\", \"estimator\", \"distribution\"},\n",
    "}\n",
    "\n",
    "\n",
    "# Define baseline classifier\n",
    "baseline_classifier = DictionaryModel(keywords=label_keywords, labelorder=labels)\n",
    "\n",
    "# Predict and score\n",
    "print(\"Performance on Train\")\n",
    "y_train_pred = baseline_classifier.predict(X_train)\n",
    "print(classification_report(y_train, list(y_train_pred)))\n",
    "\n",
    "print(\"Performance on Validation\")\n",
    "y_val_pred = baseline_classifier.predict(X_val)\n",
    "print(classification_report(y_val, list(y_val_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not too great, but given that each label only applies to about 8% of papers, not too shabby neither. A quick win here could be too manually delete the terms which are clearly very broad. \n",
    "\n",
    "Let's do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/walkenho/.cache/pypoetry/virtualenvs/arxiv-article-classifier-IjPt3q2a-py3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.45      0.53       886\n",
      "           1       0.40      0.69      0.51       817\n",
      "           2       0.49      0.13      0.21       661\n",
      "           3       0.59      0.55      0.57       607\n",
      "           4       0.53      0.50      0.51      1990\n",
      "           5       0.32      0.26      0.29       600\n",
      "           6       0.95      0.46      0.62       726\n",
      "           7       0.35      0.43      0.39       612\n",
      "           8       0.91      0.51      0.65       601\n",
      "           9       0.39      0.64      0.48       634\n",
      "          10       0.13      0.29      0.18       686\n",
      "          11       0.32      0.63      0.42       611\n",
      "          12       0.28      0.59      0.38       710\n",
      "          13       0.27      0.68      0.38       603\n",
      "\n",
      "   micro avg       0.39      0.49      0.44     10744\n",
      "   macro avg       0.47      0.49      0.44     10744\n",
      "weighted avg       0.48      0.49      0.45     10744\n",
      " samples avg       0.38      0.51      0.40     10744\n",
      "\n",
      "Performance on Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.43      0.53       296\n",
      "           1       0.40      0.66      0.50       273\n",
      "           2       0.52      0.13      0.20       220\n",
      "           3       0.64      0.53      0.58       203\n",
      "           4       0.54      0.51      0.52       664\n",
      "           5       0.28      0.23      0.25       200\n",
      "           6       0.90      0.54      0.67       242\n",
      "           7       0.36      0.45      0.40       204\n",
      "           8       0.93      0.51      0.66       201\n",
      "           9       0.37      0.62      0.46       211\n",
      "          10       0.13      0.28      0.17       229\n",
      "          11       0.32      0.62      0.42       203\n",
      "          12       0.28      0.59      0.38       237\n",
      "          13       0.27      0.68      0.38       201\n",
      "\n",
      "   micro avg       0.40      0.49      0.44      3584\n",
      "   macro avg       0.47      0.48      0.44      3584\n",
      "weighted avg       0.49      0.49      0.45      3584\n",
      " samples avg       0.38      0.51      0.40      3584\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/walkenho/.cache/pypoetry/virtualenvs/arxiv-article-classifier-IjPt3q2a-py3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Define the keywords you want to use for each label\n",
    "from sklearn.metrics import classification_report\n",
    "from arxiv_article_classifier.model.baseline import DictionaryModel\n",
    "\n",
    "\n",
    "label_keywords = {\n",
    "    \"cs.CL\": {\"text\", \"llm\"},\n",
    "    \"cs.CV\": {\"feature\", \"image\"},\n",
    "    \"cs.CY\": {\"fairness\"},\n",
    "    \"cs.GT\": {\"equilibrium\", \"player\", \"game\"},\n",
    "    \"cs.LG\": {\"learning\"},\n",
    "    \"cs.MA\": {\"policy\"},\n",
    "    \"cs.RO\": {\"robot\"},\n",
    "    \"cs.SI\": {\"node\", \"graph\"},\n",
    "    \"eess.AS\": {\"audio\", \"speaker\"},\n",
    "    \"eess.SP\": {\"communication\", \"signal\", \"channel\"},\n",
    "    \"eess.SY\": {\"state\"},\n",
    "    \"math.NA\": {\"scheme\", \"numerical\"},\n",
    "    \"math.OC\": {\"optimal\", \"optimization\"},\n",
    "    \"math.ST\": {\"sample\", \"estimator\", \"distribution\"},\n",
    "}\n",
    "\n",
    "\n",
    "# Define baseline classifier\n",
    "baseline_classifier = DictionaryModel(keywords=label_keywords, labelorder=labels)\n",
    "\n",
    "# Predict and score\n",
    "print(\"Performance on Train\")\n",
    "y_train_pred = baseline_classifier.predict(X_train)\n",
    "print(classification_report(y_train, list(y_train_pred)))\n",
    "\n",
    "print(\"Performance on Validation\")\n",
    "y_val_pred = baseline_classifier.predict(X_val)\n",
    "print(classification_report(y_val, list(y_val_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah, already better. The f1-score of most categories improved. There is certainly still optimization potential, but since this is only meant to be a baseline, let's move on to the next model. In the next notebook, we will take a look at a tfidft model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arxiv-article-classifier-IjPt3q2a-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
